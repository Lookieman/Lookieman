{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lookieman/home_projects/blob/main/ThinkOnwardsComp%5CPhase2d_Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwD8FgH1iqy_"
      },
      "source": [
        "**Phase** 2d now tries to focus on improvement of performance by:\n",
        "\n",
        "\n",
        "\n",
        "*   Tweaking the parameters for teh Cosine Annealing LR\n",
        "*   Adding Sprectral Norm for Stabilized Unet\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRVNO74deCo7",
        "outputId": "dfd83c92-7048-4ceb-b0ec-aa950e04835d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Phase2a\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from scipy import ndimage\n",
        "from math import e\n",
        "\n",
        "#phase 2b\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#phase 2c\n",
        "import random\n",
        "\n",
        "#phase 2d\n",
        "from torch.nn.utils import spectral_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JhRM7dE45Hm",
        "outputId": "2667dcfd-04c1-45d8-caba-be15e563db45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "USE_ADAPTIVE_MODEL = True  # Set to True for adaptive model\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 35\n",
        "ENSEMBLE_SEEDS = [42, 123, 456]  # 3 seeds per fold\n",
        "K_FOLDS = 5\n",
        "EARLY_STOPPING_PATIENCE = 8\n",
        "GRADIENT_CLIP_NORM = 0.5\n",
        "DROPOUT=0.05\n",
        "\n",
        "\n",
        "\n",
        "data_dir = Path('/content/drive/MyDrive/ThinkOnward/Data/Train')\n",
        "result_dir = Path('/content/drive/MyDrive/ThinkOnward/Result/Phase2c')\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "#print(f\"Model type: {'Adaptive' if USE_ADAPTIVE_MODEL else 'Resize'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns9AknqeWMaA"
      },
      "outputs": [],
      "source": [
        "def setup_deterministic_training(seed):\n",
        "    \"\"\"Setup completely deterministic training environment\"\"\"\n",
        "\n",
        "    # Set all random seeds\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # Ensure deterministic behavior\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # Enable deterministic algorithms where possible\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except:\n",
        "        pass  # Not all PyTorch versions support this\n",
        "\n",
        "    print(f\"‚úÖ Deterministic training setup complete with seed {seed}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6lOdwsc48nx"
      },
      "outputs": [],
      "source": [
        "class SeismicDataset(Dataset):\n",
        "    def __init__(self, data_dir, sample_indices, use_adaptive=False):\n",
        "        self.data_dir = data_dir\n",
        "        self.sample_indices = sample_indices\n",
        "        self.use_adaptive = use_adaptive\n",
        "        self.receiver_files = [\n",
        "            'receiver_data_src_1.npy',\n",
        "            'receiver_data_src_75.npy',\n",
        "            'receiver_data_src_150.npy',\n",
        "            'receiver_data_src_225.npy',\n",
        "            'receiver_data_src_300.npy'\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_idx = self.sample_indices[idx]\n",
        "        sample_dir = os.path.join(self.data_dir, f'TrainingData_{sample_idx}')\n",
        "\n",
        "        # Load receiver data (5 files)\n",
        "        receiver_data = []\n",
        "        for file_name in self.receiver_files:\n",
        "            file_path = os.path.join(sample_dir, file_name)\n",
        "            data = np.load(file_path).astype(np.float32)  # (10001, 31)\n",
        "            receiver_data.append(data)\n",
        "\n",
        "        # Load target velocity model\n",
        "        target_path = os.path.join(sample_dir, 'vp_model.npy')\n",
        "        target = np.load(target_path).astype(np.float32)  # (300, 1259)\n",
        "\n",
        "        if self.use_adaptive:\n",
        "            # Process for adaptive model\n",
        "            processed_inputs = []\n",
        "            for data in receiver_data:\n",
        "                # 1D conv + maxpool simulation using numpy\n",
        "                # Downsample from 10001 to ~313 (factor of ~32)\n",
        "                downsampled = data[::32, :]  # (313, 31)\n",
        "\n",
        "                # Zero pad from 31 to 32 channels\n",
        "                if downsampled.shape[1] == 31:\n",
        "                    padded = np.pad(downsampled, ((0, 0), (0, 1)), mode='constant')  # (313, 32)\n",
        "                else:\n",
        "                    padded = downsampled\n",
        "\n",
        "                # Reshape to make it more compact 2D\n",
        "                # We'll treat this as (313, 32) for now and let the model handle it\n",
        "                processed_inputs.append(padded.T)  # (32, 313) for easier processing\n",
        "\n",
        "            # Stack all 5 processed inputs\n",
        "            input_tensor = np.stack(processed_inputs, axis=0)  # (5, 32, 313)\n",
        "        else:\n",
        "            # Process for resize model\n",
        "            processed_inputs = []\n",
        "            for data in receiver_data:\n",
        "                # Resize (10001, 31) to (300, 1259)\n",
        "                resized = ndimage.zoom(data, (300/10001, 1259/31), order=1)\n",
        "                processed_inputs.append(resized)\n",
        "\n",
        "            # Stack all 5 processed inputs\n",
        "            input_tensor = np.stack(processed_inputs, axis=0)  # (5, 300, 1259)\n",
        "\n",
        "        return torch.from_numpy(input_tensor), torch.from_numpy(target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyL109Cu5JAw"
      },
      "outputs": [],
      "source": [
        "# Helper function to match tensor sizes for skip connections\n",
        "def match_tensor_size(tensor1, tensor2):\n",
        "    \"\"\"Match the spatial dimensions of tensor1 to tensor2 by cropping or padding.\"\"\"\n",
        "    _, _, h1, w1 = tensor1.shape\n",
        "    _, _, h2, w2 = tensor2.shape\n",
        "\n",
        "    # Calculate differences\n",
        "    dh = h2 - h1\n",
        "    dw = w2 - w1\n",
        "\n",
        "    if dh > 0 or dw > 0:\n",
        "        # Pad tensor1 if it's smaller\n",
        "        pad_h = max(0, dh)\n",
        "        pad_w = max(0, dw)\n",
        "        tensor1 = F.pad(tensor1, (0, pad_w, 0, pad_h))\n",
        "    elif dh < 0 or dw < 0:\n",
        "        # Crop tensor1 if it's larger\n",
        "        tensor1 = tensor1[:, :, :h2, :w2]\n",
        "\n",
        "    return tensor1\n",
        "\n",
        "# MAPE Loss Function\n",
        "def mape_loss(predictions, targets, epsilon=1e-8):\n",
        "    targets_safe = torch.clamp(torch.abs(targets), min=epsilon)\n",
        "    return torch.mean(torch.abs((targets - predictions) / targets_safe)) * 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoieEO_S5ASQ"
      },
      "outputs": [],
      "source": [
        "# Attention Block\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, dropout=0.05):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
        "        self.conv3 = nn.Conv2d(in_channels, in_channels, 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout2d(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "\n",
        "        query = self.conv1(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
        "        key = self.conv2(x).view(batch_size, -1, width * height)\n",
        "        value = self.conv3(x).view(batch_size, -1, width * height)\n",
        "\n",
        "        attention = torch.bmm(query, key)\n",
        "        attention = self.softmax(attention)\n",
        "\n",
        "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, channels, height, width)\n",
        "\n",
        "        return self.gamma * out + x\n",
        "\n",
        "# Double Convolution Block\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.05):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout),  # Add dropout\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "# U-Net Model\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=5, out_channels=1, use_adaptive=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.use_adaptive = use_adaptive\n",
        "\n",
        "        if use_adaptive:\n",
        "            # First process the irregular input\n",
        "            self.input_processor = nn.Sequential(\n",
        "                nn.Conv2d(5, 16, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "            # Input will be (5, 32, 313), output will be (32, 32, 313)\n",
        "            in_channels = 32\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = DoubleConv(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = DoubleConv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = DoubleConv(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = DoubleConv(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        # Bottleneck with attention\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "        self.attention = AttentionBlock(1024)\n",
        "\n",
        "        # Decoder\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
        "        self.dec4 = DoubleConv(1024, 512)\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.dec3 = DoubleConv(512, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec2 = DoubleConv(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec1 = DoubleConv(128, 64)\n",
        "\n",
        "        # Final output\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, 1)\n",
        "\n",
        "        if use_adaptive:\n",
        "            # Final upsampling to reach (300, 1259)\n",
        "            self.final_upsample = nn.Sequential(\n",
        "                nn.ConvTranspose2d(1, 1, kernel_size=4, stride=2, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_adaptive:\n",
        "            # Process irregular input first\n",
        "            x = self.input_processor(x)  # (batch, 32, 32, 313)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(self.pool4(e4))\n",
        "        b = self.attention(b)\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        d4 = self.up4(b)\n",
        "        d4 = match_tensor_size(d4, e4)\n",
        "        d4 = torch.cat([d4, e4], dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "\n",
        "        d3 = self.up3(d4)\n",
        "        d3 = match_tensor_size(d3, e3)\n",
        "        d3 = torch.cat([d3, e3], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = match_tensor_size(d2, e2)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = match_tensor_size(d1, e1)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        # Final output\n",
        "        output = self.final_conv(d1)\n",
        "\n",
        "        if self.use_adaptive:\n",
        "            # Upsample to final target size (300, 1259)\n",
        "            output = F.interpolate(output, size=(300, 1259), mode='bilinear', align_corners=False)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC0Eyl_H5x38"
      },
      "outputs": [],
      "source": [
        "class StabilizedUNet(nn.Module):\n",
        "    def __init__(self, in_channels=5, out_channels=1, use_adaptive=True, dropout=0.05):\n",
        "        super(StabilizedUNet, self).__init__()\n",
        "        self.use_adaptive = use_adaptive\n",
        "\n",
        "        if use_adaptive:\n",
        "            self.input_processor = nn.Sequential(\n",
        "                nn.Conv2d(5, 16, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(16),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(dropout),\n",
        "                nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "            in_channels = 32\n",
        "\n",
        "        # Encoder with dropout\n",
        "        self.enc1 = DoubleConv(in_channels, 64, dropout)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = DoubleConv(64, 128, dropout)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = DoubleConv(128, 256, dropout)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = DoubleConv(256, 512, dropout)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        # Bottleneck with attention\n",
        "        self.bottleneck = DoubleConv(512, 1024, dropout)\n",
        "        self.attention = AttentionBlock(1024, dropout)\n",
        "\n",
        "        # Decoder\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
        "        self.dec4 = DoubleConv(1024, 512, dropout)\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.dec3 = DoubleConv(512, 256, dropout)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec2 = DoubleConv(256, 128, dropout)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec1 = DoubleConv(128, 64, dropout)\n",
        "\n",
        "        # Final output\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, 1)\n",
        "\n",
        "        # Initialize weights for stability\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Stable weight initialization\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.ConvTranspose2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_adaptive:\n",
        "            x = self.input_processor(x)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(self.pool4(e4))\n",
        "        b = self.attention(b)\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        d4 = self.up4(b)\n",
        "        d4 = self._match_tensor_size(d4, e4)\n",
        "        d4 = torch.cat([d4, e4], dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "\n",
        "        d3 = self.up3(d4)\n",
        "        d3 = self._match_tensor_size(d3, e3)\n",
        "        d3 = torch.cat([d3, e3], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = self._match_tensor_size(d2, e2)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = self._match_tensor_size(d1, e1)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        # Final output\n",
        "        output = self.final_conv(d1)\n",
        "\n",
        "        if self.use_adaptive:\n",
        "            output = F.interpolate(output, size=(300, 1259), mode='bilinear', align_corners=False)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def _match_tensor_size(self, tensor1, tensor2):\n",
        "        \"\"\"Helper function for matching tensor sizes\"\"\"\n",
        "        _, _, h1, w1 = tensor1.shape\n",
        "        _, _, h2, w2 = tensor2.shape\n",
        "\n",
        "        dh = h2 - h1\n",
        "        dw = w2 - w1\n",
        "\n",
        "        if dh > 0 or dw > 0:\n",
        "            pad_h = max(0, dh)\n",
        "            pad_w = max(0, dw)\n",
        "            tensor1 = F.pad(tensor1, (0, pad_w, 0, pad_h))\n",
        "        elif dh < 0 or dw < 0:\n",
        "            tensor1 = tensor1[:, :, :h2, :w2]\n",
        "\n",
        "        return tensor1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AGS5m7gWfZN"
      },
      "outputs": [],
      "source": [
        "def train_epoch_fast(model, train_loader, optimizer):\n",
        "    \"\"\"Fast training epoch without progress bars\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(DEVICE, non_blocking=True), targets.to(DEVICE, non_blocking=True)\n",
        "        targets = targets.unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = mape_loss(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=GRADIENT_CLIP_NORM)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        # Minimal memory cleanup\n",
        "        if batch_idx % 20 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def validate_epoch_fast(model, val_loader):\n",
        "    \"\"\"Fast validation epoch without progress bars\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.to(DEVICE, non_blocking=True), targets.to(DEVICE, non_blocking=True)\n",
        "            targets = targets.unsqueeze(1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = mape_loss(outputs, targets)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Minimal memory cleanup\n",
        "            if batch_idx % 20 == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def fast_train_single_fold(data_dir, fold_info, seed, result_dir):\n",
        "    \"\"\"Streamlined single fold training with specific seed\"\"\"\n",
        "\n",
        "    # AGGRESSIVE MEMORY CLEANUP AT START\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "    gc.collect()\n",
        "\n",
        "    fold_num = fold_info['fold']\n",
        "\n",
        "    print(f\"üöÄ Training Fold {fold_num} with Seed {seed}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Setup deterministic training\n",
        "    setup_deterministic_training(seed)\n",
        "\n",
        "    # Create model\n",
        "    model = StabilizedUNet(in_channels=5, out_channels=1, use_adaptive=USE_ADAPTIVE_MODEL,dropout=DROPOUT)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # Optimized DataLoader settings for A100\n",
        "    train_dataset = SeismicDataset(data_dir, fold_info['train_indices'], use_adaptive=USE_ADAPTIVE_MODEL)\n",
        "    val_dataset = SeismicDataset(data_dir, fold_info['val_indices'], use_adaptive=USE_ADAPTIVE_MODEL)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=2,  # Optimized for stability\n",
        "        pin_memory=True,\n",
        "        persistent_workers=False,  # More stable\n",
        "        prefetch_factor=1\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=False,\n",
        "        prefetch_factor=1\n",
        "    )\n",
        "\n",
        "    # Optimizer and scheduler\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.005)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
        "\n",
        "    # Training tracking\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    epoch_times = []\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # Train and validate\n",
        "        train_loss = train_epoch_fast(model, train_loader, optimizer)\n",
        "        val_loss = validate_epoch_fast(model, val_loader)\n",
        "\n",
        "        # Update scheduler\n",
        "        old_lr = optimizer.param_groups[0]['lr']\n",
        "        scheduler.step(val_loss)\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Track metrics\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        epoch_times.append(epoch_time)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Progress reporting (minimal)\n",
        "        if epoch % 5 == 0 or val_loss < best_val_loss:\n",
        "            print(f\"  Epoch {epoch+1:2d}: Train={train_loss:.4f}%, Val={val_loss:.4f}%, LR={current_lr:.6f}, Time={epoch_time:.1f}s\")\n",
        "\n",
        "        # Learning rate change notification\n",
        "        if current_lr != old_lr:\n",
        "            print(f\"    üìâ Learning rate reduced: {old_lr:.2e} ‚Üí {current_lr:.2e}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "\n",
        "            # Save model checkpoint\n",
        "            model_path = result_dir / f'model_fold_{fold_num}_seed_{seed}.pth'\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'val_loss': best_val_loss,\n",
        "                'fold': fold_num,\n",
        "                'seed': seed,\n",
        "                'train_losses': train_losses,\n",
        "                'val_losses': val_losses\n",
        "            }, model_path)\n",
        "\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
        "            print(f\"    ‚èπÔ∏è  Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        if current_lr < 1e-7:\n",
        "            print(f\"    ‚èπÔ∏è  Learning rate too low: {current_lr:.2e}\")\n",
        "            break\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"‚úÖ Fold {fold_num} Seed {seed} complete: Best Val MAPE = {best_val_loss:.4f}% in {total_time/60:.1f}min\")\n",
        "\n",
        "    # Cleanup\n",
        "    del model, optimizer, scheduler, train_loader, val_loader\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return {\n",
        "        'fold': fold_num,\n",
        "        'seed': seed,\n",
        "        'best_val_loss': best_val_loss,\n",
        "        'final_epoch': epoch + 1,\n",
        "        'total_time': total_time,\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'avg_epoch_time': np.mean(epoch_times)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vFX5LRxXVmV"
      },
      "outputs": [],
      "source": [
        "class OptimizedMultiSeedTrainer:\n",
        "    def __init__(self, data_dir, result_dir, k_folds=5, seeds=None):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.result_dir = Path(result_dir)\n",
        "        self.k_folds = k_folds\n",
        "        self.seeds = seeds or ENSEMBLE_SEEDS\n",
        "        self.results = {}\n",
        "\n",
        "        # Create results directory\n",
        "        self.result_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(f\"üéØ Multi-Seed Trainer initialized\")\n",
        "        print(f\"   Data: {self.data_dir}\")\n",
        "        print(f\"   Results: {self.result_dir}\")\n",
        "        print(f\"   Seeds: {self.seeds}\")\n",
        "        print(f\"   Total models to train: {k_folds * len(self.seeds)}\")\n",
        "\n",
        "    def create_kfold_splits(self, dataset_size=2000):\n",
        "        \"\"\"Create K-fold splits (same as Phase 2b)\"\"\"\n",
        "        indices = np.arange(1, dataset_size + 1)\n",
        "        kfold = KFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "        splits = []\n",
        "        for fold, (train_idx, val_idx) in enumerate(kfold.split(indices)):\n",
        "            train_samples = indices[train_idx]\n",
        "            val_samples = indices[val_idx]\n",
        "\n",
        "            splits.append({\n",
        "                'fold': fold,\n",
        "                'train_indices': train_samples,\n",
        "                'val_indices': val_samples,\n",
        "                'train_size': len(train_samples),\n",
        "                'val_size': len(val_samples)\n",
        "            })\n",
        "\n",
        "        print(f\"üìä Created {self.k_folds}-fold splits\")\n",
        "        return splits\n",
        "\n",
        "    def train_fold_ensemble(self, fold_info):\n",
        "        \"\"\"Train multiple seeds for single fold\"\"\"\n",
        "        fold_num = fold_info['fold']\n",
        "        fold_results = []\n",
        "\n",
        "        print(f\"\\nüéØ Training Fold {fold_num} with {len(self.seeds)} seeds\")\n",
        "        fold_start_time = time.time()\n",
        "\n",
        "        for seed in self.seeds:\n",
        "            try:\n",
        "                result = fast_train_single_fold(self.data_dir, fold_info, seed, self.result_dir)\n",
        "                fold_results.append(result)\n",
        "\n",
        "                # Brief pause between models\n",
        "                time.sleep(2)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error training Fold {fold_num} Seed {seed}: {str(e)}\")\n",
        "                fold_results.append({\n",
        "                    'fold': fold_num,\n",
        "                    'seed': seed,\n",
        "                    'best_val_loss': float('inf'),\n",
        "                    'error': str(e)\n",
        "                })\n",
        "\n",
        "        fold_time = time.time() - fold_start_time\n",
        "\n",
        "        # Analyze fold ensemble\n",
        "        valid_results = [r for r in fold_results if 'error' not in r]\n",
        "        if valid_results:\n",
        "            performances = [r['best_val_loss'] for r in valid_results]\n",
        "            mean_perf = np.mean(performances)\n",
        "            std_perf = np.std(performances)\n",
        "            best_perf = np.min(performances)\n",
        "\n",
        "            print(f\"üìà Fold {fold_num} ensemble results:\")\n",
        "            print(f\"   Mean MAPE: {mean_perf:.4f}% ¬± {std_perf:.4f}%\")\n",
        "            print(f\"   Best MAPE: {best_perf:.4f}%\")\n",
        "            print(f\"   Seeds: {[r['seed'] for r in valid_results]}\")\n",
        "            print(f\"   Time: {fold_time/60:.1f} minutes\")\n",
        "\n",
        "        return fold_results\n",
        "\n",
        "    def run_full_training(self):\n",
        "        \"\"\"Run complete multi-seed ensemble training\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"üöÄ STARTING OPTIMIZED MULTI-SEED ENSEMBLE TRAINING\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Create fold splits\n",
        "        splits = self.create_kfold_splits()\n",
        "\n",
        "        # Train all folds\n",
        "        all_results = {}\n",
        "        for fold_info in splits:\n",
        "            fold_results = self.train_fold_ensemble(fold_info)\n",
        "            all_results[fold_info['fold']] = fold_results\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "\n",
        "        # Comprehensive analysis\n",
        "        self.analyze_results(all_results, total_time)\n",
        "\n",
        "        # Save results\n",
        "        self.save_results(all_results)\n",
        "\n",
        "        return all_results\n",
        "\n",
        "    def analyze_results(self, all_results, total_time):\n",
        "        \"\"\"Comprehensive results analysis\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"üìä COMPREHENSIVE ENSEMBLE ANALYSIS\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Extract all valid results\n",
        "        all_performances = []\n",
        "        fold_best = []\n",
        "        fold_ensembles = []\n",
        "\n",
        "        print(f\"\\nüìã Individual Fold Analysis:\")\n",
        "        print(f\"{'Fold':<6} {'Best':<8} {'Mean':<8} {'Std':<8} {'Seeds':<12}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        for fold_num in range(self.k_folds):\n",
        "            fold_results = all_results[fold_num]\n",
        "            valid_results = [r for r in fold_results if 'error' not in r]\n",
        "\n",
        "            if valid_results:\n",
        "                performances = [r['best_val_loss'] for r in valid_results]\n",
        "                all_performances.extend(performances)\n",
        "\n",
        "                fold_mean = np.mean(performances)\n",
        "                fold_std = np.std(performances)\n",
        "                fold_min = np.min(performances)\n",
        "\n",
        "                fold_best.append(fold_min)\n",
        "                fold_ensembles.append(fold_mean)\n",
        "\n",
        "                print(f\"{fold_num:<6} {fold_min:<8.4f} {fold_mean:<8.4f} {fold_std:<8.4f} {len(valid_results):<12}\")\n",
        "            else:\n",
        "                print(f\"{fold_num:<6} {'FAILED':<8} {'FAILED':<8} {'FAILED':<8} {'0':<12}\")\n",
        "                fold_best.append(float('inf'))\n",
        "                fold_ensembles.append(float('inf'))\n",
        "\n",
        "        # Overall statistics\n",
        "        if all_performances:\n",
        "            overall_mean = np.mean(all_performances)\n",
        "            overall_std = np.std(all_performances)\n",
        "            overall_best = np.min(all_performances)\n",
        "            ensemble_mean = np.mean(fold_ensembles)\n",
        "\n",
        "            print(f\"\\nüéØ Overall Performance Summary:\")\n",
        "            print(f\"   Total models trained: {len(all_performances)}\")\n",
        "            print(f\"   Overall mean MAPE: {overall_mean:.4f}% ¬± {overall_std:.4f}%\")\n",
        "            print(f\"   Best single model: {overall_best:.4f}%\")\n",
        "            print(f\"   Expected ensemble MAPE: {ensemble_mean:.4f}%\")\n",
        "            print(f\"   Total training time: {total_time/3600:.2f} hours\")\n",
        "            print(f\"   Average time per model: {total_time/len(all_performances)/60:.1f} minutes\")\n",
        "\n",
        "            # Performance improvements\n",
        "            best_fold_mean = np.mean(fold_best)\n",
        "            print(f\"\\nüìà Performance Analysis:\")\n",
        "            print(f\"   Best single fold performance: {np.min(fold_best):.4f}%\")\n",
        "            print(f\"   Mean of best fold performances: {best_fold_mean:.4f}%\")\n",
        "            print(f\"   Stability improvement: {overall_std:.4f}% standard deviation\")\n",
        "\n",
        "            # Competition readiness\n",
        "            target_performance = 3.0\n",
        "            models_below_target = sum(1 for p in all_performances if p < target_performance)\n",
        "            print(f\"\\nüèÜ Competition Analysis:\")\n",
        "            print(f\"   Models below 3.0% target: {models_below_target}/{len(all_performances)}\")\n",
        "            print(f\"   Success rate: {models_below_target/len(all_performances)*100:.1f}%\")\n",
        "\n",
        "            if overall_best < target_performance:\n",
        "                print(f\"   üéâ TARGET ACHIEVED! Best model: {overall_best:.4f}%\")\n",
        "            else:\n",
        "                gap = overall_best - target_performance\n",
        "                print(f\"   üéØ Gap to target: {gap:.4f}%\")\n",
        "\n",
        "    def save_results(self, all_results):\n",
        "        \"\"\"Save comprehensive results\"\"\"\n",
        "        import json\n",
        "\n",
        "        # Save detailed results\n",
        "        results_file = self.result_dir / 'ensemble_results.json'\n",
        "\n",
        "        # Convert to JSON-serializable format\n",
        "        json_results = {}\n",
        "        for fold_num, fold_results in all_results.items():\n",
        "            json_results[f'fold_{fold_num}'] = []\n",
        "            for result in fold_results:\n",
        "                json_result = {k: v for k, v in result.items() if k not in ['train_losses', 'val_losses']}\n",
        "                json_results[f'fold_{fold_num}'].append(json_result)\n",
        "\n",
        "        with open(results_file, 'w') as f:\n",
        "            json.dump(json_results, f, indent=2)\n",
        "\n",
        "        # Create summary file\n",
        "        summary_file = self.result_dir / 'training_summary.txt'\n",
        "        with open(summary_file, 'w') as f:\n",
        "            f.write(\"Phase 2c Multi-Seed Ensemble Training Summary\\n\")\n",
        "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "            for fold_num in range(self.k_folds):\n",
        "                fold_results = all_results[fold_num]\n",
        "                valid_results = [r for r in fold_results if 'error' not in r]\n",
        "\n",
        "                if valid_results:\n",
        "                    performances = [r['best_val_loss'] for r in valid_results]\n",
        "                    f.write(f\"Fold {fold_num}:\\n\")\n",
        "                    f.write(f\"  Best: {np.min(performances):.4f}%\\n\")\n",
        "                    f.write(f\"  Mean: {np.mean(performances):.4f}% ¬± {np.std(performances):.4f}%\\n\")\n",
        "                    f.write(f\"  Seeds: {[r['seed'] for r in valid_results]}\\n\\n\")\n",
        "\n",
        "        print(f\"üíæ Results saved to:\")\n",
        "        print(f\"   {results_file}\")\n",
        "        print(f\"   {summary_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82Q-iexRXpMr"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # Set memory management environment variable\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "    # Setup paths\n",
        "\n",
        "    data_dir = Path('/content/drive/MyDrive/ThinkOnward/Data/Train')\n",
        "    result_dir = Path('/content/drive/MyDrive/ThinkOnward/Result/Phase2c')\n",
        "\n",
        "    print(f\"üîß Phase 2c Optimized Training Pipeline\")\n",
        "    print(f\"   Target: Sub-3.0% MAPE with stable ensemble\")\n",
        "    print(f\"   Strategy: {K_FOLDS} folds √ó {len(ENSEMBLE_SEEDS)} seeds = {K_FOLDS * len(ENSEMBLE_SEEDS)} models\")\n",
        "    print(f\"   Hardware: A100 GPU with batch_size={BATCH_SIZE}\")\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = OptimizedMultiSeedTrainer(\n",
        "        data_dir=data_dir,\n",
        "        result_dir=result_dir,\n",
        "        k_folds=K_FOLDS,\n",
        "        seeds=ENSEMBLE_SEEDS\n",
        "    )\n",
        "\n",
        "    # Run training\n",
        "    results = trainer.run_full_training()\n",
        "\n",
        "    print(f\"\\n‚úÖ Phase 2c Training Complete!\")\n",
        "    print(f\"Ready for diffusion model development in Phase 3\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KKucxFXXXme",
        "collapsed": true,
        "outputId": "4b7c1a34-3005-4735-e235-99fa5b969cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Phase 2c Optimized Training Pipeline\n",
            "   Target: Sub-3.0% MAPE with stable ensemble\n",
            "   Strategy: 5 folds √ó 3 seeds = 15 models\n",
            "   Hardware: A100 GPU with batch_size=32\n",
            "üéØ Multi-Seed Trainer initialized\n",
            "   Data: /content/drive/MyDrive/ThinkOnward/Data/Train\n",
            "   Results: /content/drive/MyDrive/ThinkOnward/Result/Phase2c\n",
            "   Seeds: [42, 123, 456]\n",
            "   Total models to train: 15\n",
            "\n",
            "============================================================\n",
            "üöÄ STARTING OPTIMIZED MULTI-SEED ENSEMBLE TRAINING\n",
            "============================================================\n",
            "üìä Created 5-fold splits\n",
            "\n",
            "üéØ Training Fold 0 with 3 seeds\n",
            "üöÄ Training Fold 0 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-5cad78f6f013>:18: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:217.)\n",
            "  attention = torch.bmm(query, key)\n",
            "<ipython-input-6-5cad78f6f013>:21: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:217.)\n",
            "  out = torch.bmm(value, attention.permute(0, 2, 1))\n",
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:217.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch  1: Train=77.3063%, Val=95.8216%, LR=0.000050, Time=1680.4s\n",
            "  Epoch  2: Train=57.2865%, Val=54.2104%, LR=0.000050, Time=34.5s\n",
            "  Epoch  3: Train=50.6860%, Val=48.6783%, LR=0.000050, Time=41.7s\n",
            "  Epoch  5: Train=45.3088%, Val=48.0459%, LR=0.000050, Time=33.0s\n",
            "  Epoch  6: Train=43.3685%, Val=43.2842%, LR=0.000050, Time=41.8s\n",
            "  Epoch  7: Train=41.6620%, Val=41.8366%, LR=0.000050, Time=41.7s\n",
            "  Epoch  9: Train=38.3403%, Val=39.6044%, LR=0.000050, Time=32.6s\n",
            "  Epoch 11: Train=35.1564%, Val=29.5073%, LR=0.000050, Time=33.1s\n",
            "  Epoch 16: Train=28.5392%, Val=38.6225%, LR=0.000050, Time=33.0s\n",
            "    üìâ Learning rate reduced: 5.00e-05 ‚Üí 2.50e-05\n",
            "  Epoch 19: Train=25.5515%, Val=29.3514%, LR=0.000025, Time=33.0s\n",
            "  Epoch 21: Train=24.1497%, Val=24.8773%, LR=0.000025, Time=33.1s\n",
            "  Epoch 26: Train=21.2963%, Val=24.2036%, LR=0.000025, Time=33.7s\n",
            "‚úÖ Fold 0 Seed 42 complete: Best Val MAPE = 24.2036% in 45.7min\n",
            "üöÄ Training Fold 0 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=86.4768%, Val=100.8492%, LR=0.000050, Time=33.1s\n",
            "  Epoch  2: Train=70.9706%, Val=84.2635%, LR=0.000050, Time=34.2s\n",
            "  Epoch  3: Train=63.5841%, Val=63.2556%, LR=0.000050, Time=42.3s\n",
            "  Epoch  4: Train=58.7907%, Val=61.1778%, LR=0.000050, Time=42.2s\n",
            "  Epoch  5: Train=55.8156%, Val=59.1872%, LR=0.000050, Time=41.8s\n",
            "  Epoch  6: Train=53.4014%, Val=54.1154%, LR=0.000050, Time=42.2s\n",
            "  Epoch  8: Train=49.4387%, Val=50.2404%, LR=0.000050, Time=33.1s\n",
            "  Epoch  9: Train=47.7307%, Val=44.3797%, LR=0.000050, Time=42.0s\n",
            "  Epoch 11: Train=44.4940%, Val=48.6576%, LR=0.000050, Time=33.4s\n",
            "  Epoch 12: Train=42.8740%, Val=40.6776%, LR=0.000050, Time=34.0s\n",
            "  Epoch 16: Train=36.7913%, Val=43.2344%, LR=0.000050, Time=33.4s\n",
            "  Epoch 17: Train=35.3306%, Val=39.2807%, LR=0.000050, Time=33.3s\n",
            "  Epoch 21: Train=29.8100%, Val=44.0120%, LR=0.000050, Time=33.9s\n",
            "  Epoch 23: Train=27.0822%, Val=31.9099%, LR=0.000050, Time=33.4s\n",
            "  Epoch 25: Train=24.2245%, Val=28.5073%, LR=0.000050, Time=33.0s\n",
            "  Epoch 26: Train=22.6551%, Val=27.2852%, LR=0.000050, Time=42.3s\n",
            "  Epoch 28: Train=19.7385%, Val=26.7615%, LR=0.000050, Time=33.1s\n",
            "‚úÖ Fold 0 Seed 123 complete: Best Val MAPE = 26.7615% in 18.8min\n",
            "üöÄ Training Fold 0 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=74.7937%, Val=95.8180%, LR=0.000050, Time=33.0s\n",
            "  Epoch  2: Train=59.7373%, Val=57.6253%, LR=0.000050, Time=34.4s\n",
            "  Epoch  3: Train=53.4028%, Val=51.9477%, LR=0.000050, Time=42.1s\n",
            "  Epoch  4: Train=49.2429%, Val=48.0961%, LR=0.000050, Time=41.6s\n",
            "  Epoch  5: Train=46.2564%, Val=45.8759%, LR=0.000050, Time=41.6s\n",
            "  Epoch  6: Train=44.0288%, Val=44.5556%, LR=0.000050, Time=42.4s\n",
            "  Epoch  7: Train=42.1218%, Val=43.0721%, LR=0.000050, Time=42.5s\n",
            "  Epoch 10: Train=37.3151%, Val=37.4727%, LR=0.000050, Time=32.7s\n",
            "  Epoch 11: Train=35.5883%, Val=41.5690%, LR=0.000050, Time=41.7s\n",
            "  Epoch 14: Train=31.2394%, Val=37.3139%, LR=0.000050, Time=32.9s\n",
            "  Epoch 16: Train=28.5676%, Val=39.9960%, LR=0.000050, Time=32.9s\n",
            "  Epoch 17: Train=27.3910%, Val=33.1519%, LR=0.000050, Time=32.9s\n",
            "  Epoch 18: Train=26.3190%, Val=29.3159%, LR=0.000050, Time=41.8s\n",
            "  Epoch 21: Train=22.9539%, Val=37.3852%, LR=0.000050, Time=33.3s\n",
            "  Epoch 23: Train=20.6842%, Val=23.6903%, LR=0.000050, Time=33.0s\n",
            "  Epoch 25: Train=18.4749%, Val=21.9990%, LR=0.000050, Time=33.1s\n",
            "  Epoch 26: Train=17.4713%, Val=36.5006%, LR=0.000050, Time=41.5s\n",
            "  Epoch 28: Train=15.3371%, Val=16.3603%, LR=0.000050, Time=33.2s\n",
            "‚úÖ Fold 0 Seed 456 complete: Best Val MAPE = 16.3603% in 18.7min\n",
            "üìà Fold 0 ensemble results:\n",
            "   Mean MAPE: 22.4418% ¬± 4.4253%\n",
            "   Best MAPE: 16.3603%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 83.3 minutes\n",
            "\n",
            "üéØ Training Fold 1 with 3 seeds\n",
            "üöÄ Training Fold 1 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=77.4947%, Val=95.1139%, LR=0.000050, Time=33.7s\n",
            "  Epoch  2: Train=57.3930%, Val=54.0129%, LR=0.000050, Time=35.0s\n",
            "  Epoch  3: Train=50.7044%, Val=48.8871%, LR=0.000050, Time=42.3s\n",
            "  Epoch  4: Train=47.6373%, Val=46.5788%, LR=0.000050, Time=42.1s\n",
            "  Epoch  5: Train=45.3264%, Val=44.7250%, LR=0.000050, Time=41.8s\n",
            "  Epoch  6: Train=43.3883%, Val=46.3476%, LR=0.000050, Time=42.3s\n",
            "  Epoch  7: Train=41.7715%, Val=42.4220%, LR=0.000050, Time=33.1s\n",
            "  Epoch  9: Train=38.7916%, Val=39.9528%, LR=0.000050, Time=33.6s\n",
            "  Epoch 10: Train=37.3432%, Val=37.9562%, LR=0.000050, Time=42.4s\n",
            "  Epoch 11: Train=35.9423%, Val=42.0362%, LR=0.000050, Time=42.9s\n",
            "  Epoch 16: Train=29.4375%, Val=32.5228%, LR=0.000050, Time=33.0s\n",
            "  Epoch 21: Train=23.1901%, Val=37.6262%, LR=0.000050, Time=33.6s\n",
            "    üìâ Learning rate reduced: 5.00e-05 ‚Üí 2.50e-05\n",
            "  Epoch 23: Train=20.8800%, Val=30.6929%, LR=0.000025, Time=33.4s\n",
            "  Epoch 26: Train=19.1971%, Val=32.5099%, LR=0.000025, Time=33.7s\n",
            "  Epoch 27: Train=18.6412%, Val=28.7219%, LR=0.000025, Time=33.2s\n",
            "  Epoch 28: Train=18.1592%, Val=20.7915%, LR=0.000025, Time=42.2s\n",
            "  Epoch 30: Train=17.0528%, Val=20.0989%, LR=0.000025, Time=33.4s\n",
            "‚úÖ Fold 1 Seed 42 complete: Best Val MAPE = 20.0989% in 18.6min\n",
            "üöÄ Training Fold 1 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=86.4823%, Val=100.4386%, LR=0.000050, Time=40.6s\n",
            "  Epoch  2: Train=70.9115%, Val=84.4625%, LR=0.000050, Time=32.9s\n",
            "  Epoch  3: Train=63.5893%, Val=63.1656%, LR=0.000050, Time=41.5s\n",
            "  Epoch  4: Train=58.8001%, Val=51.7413%, LR=0.000050, Time=42.2s\n",
            "  Epoch  6: Train=53.6230%, Val=54.7369%, LR=0.000050, Time=33.3s\n",
            "  Epoch  8: Train=49.7594%, Val=50.8052%, LR=0.000050, Time=32.8s\n",
            "  Epoch  9: Train=48.1745%, Val=48.9804%, LR=0.000050, Time=41.9s\n",
            "  Epoch 10: Train=46.3747%, Val=46.0516%, LR=0.000050, Time=42.1s\n",
            "  Epoch 11: Train=44.6802%, Val=49.2741%, LR=0.000050, Time=41.8s\n",
            "  Epoch 12: Train=43.0515%, Val=37.0691%, LR=0.000050, Time=32.8s\n",
            "  Epoch 13: Train=41.5403%, Val=35.4482%, LR=0.000050, Time=41.3s\n",
            "  Epoch 16: Train=36.9163%, Val=45.1000%, LR=0.000050, Time=33.5s\n",
            "    üìâ Learning rate reduced: 5.00e-05 ‚Üí 2.50e-05\n",
            "  Epoch 21: Train=30.5224%, Val=43.1797%, LR=0.000025, Time=32.7s\n",
            "    ‚èπÔ∏è  Early stopping at epoch 21\n",
            "‚úÖ Fold 1 Seed 123 complete: Best Val MAPE = 35.4482% in 13.0min\n",
            "üöÄ Training Fold 1 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=74.7777%, Val=96.2535%, LR=0.000050, Time=33.1s\n",
            "  Epoch  2: Train=59.6983%, Val=59.7111%, LR=0.000050, Time=34.0s\n",
            "  Epoch  3: Train=53.2445%, Val=51.8935%, LR=0.000050, Time=41.9s\n",
            "  Epoch  4: Train=49.0354%, Val=48.4762%, LR=0.000050, Time=42.1s\n",
            "  Epoch  5: Train=46.0099%, Val=46.0525%, LR=0.000050, Time=41.4s\n",
            "  Epoch  6: Train=43.7543%, Val=45.2078%, LR=0.000050, Time=42.3s\n",
            "  Epoch  7: Train=41.8539%, Val=43.3285%, LR=0.000050, Time=42.3s\n",
            "  Epoch  8: Train=40.0996%, Val=41.6207%, LR=0.000050, Time=41.8s\n",
            "  Epoch 10: Train=36.9265%, Val=38.6794%, LR=0.000050, Time=33.0s\n",
            "  Epoch 11: Train=35.5540%, Val=41.8786%, LR=0.000050, Time=42.2s\n",
            "  Epoch 14: Train=31.5869%, Val=30.7287%, LR=0.000050, Time=33.1s\n",
            "  Epoch 16: Train=29.0172%, Val=36.8133%, LR=0.000050, Time=33.0s\n",
            "  Epoch 18: Train=26.5204%, Val=29.0453%, LR=0.000050, Time=33.3s\n",
            "  Epoch 21: Train=22.7476%, Val=37.9293%, LR=0.000050, Time=33.7s\n",
            "  Epoch 22: Train=21.5620%, Val=26.2442%, LR=0.000050, Time=33.4s\n",
            "  Epoch 25: Train=18.1394%, Val=22.9015%, LR=0.000050, Time=33.6s\n",
            "  Epoch 26: Train=16.9131%, Val=21.0055%, LR=0.000050, Time=42.2s\n",
            "  Epoch 27: Train=15.7346%, Val=20.7394%, LR=0.000050, Time=42.5s\n",
            "  Epoch 28: Train=14.6239%, Val=19.6279%, LR=0.000050, Time=42.1s\n",
            "  Epoch 29: Train=13.6144%, Val=19.5369%, LR=0.000050, Time=41.9s\n",
            "‚úÖ Fold 1 Seed 456 complete: Best Val MAPE = 19.5369% in 19.3min\n",
            "üìà Fold 1 ensemble results:\n",
            "   Mean MAPE: 25.0280% ¬± 7.3718%\n",
            "   Best MAPE: 19.5369%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 51.0 minutes\n",
            "\n",
            "üéØ Training Fold 2 with 3 seeds\n",
            "üöÄ Training Fold 2 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=77.4318%, Val=96.4046%, LR=0.000050, Time=33.1s\n",
            "  Epoch  2: Train=57.4093%, Val=50.0413%, LR=0.000050, Time=34.5s\n",
            "  Epoch  4: Train=47.5453%, Val=46.6006%, LR=0.000050, Time=33.3s\n",
            "  Epoch  5: Train=45.2809%, Val=44.0668%, LR=0.000050, Time=41.6s\n",
            "  Epoch  6: Train=43.4891%, Val=42.4074%, LR=0.000050, Time=41.3s\n",
            "  Epoch  7: Train=41.9428%, Val=40.7060%, LR=0.000050, Time=41.1s\n",
            "  Epoch  9: Train=38.7333%, Val=40.4929%, LR=0.000050, Time=32.8s\n",
            "  Epoch 10: Train=37.3527%, Val=39.8439%, LR=0.000050, Time=41.7s\n",
            "  Epoch 11: Train=36.0283%, Val=40.3004%, LR=0.000050, Time=41.8s\n",
            "  Epoch 13: Train=33.5197%, Val=39.5158%, LR=0.000050, Time=33.9s\n",
            "  Epoch 14: Train=32.1421%, Val=39.3884%, LR=0.000050, Time=41.5s\n",
            "  Epoch 15: Train=30.9291%, Val=37.6497%, LR=0.000050, Time=41.6s\n",
            "  Epoch 16: Train=29.7094%, Val=39.3082%, LR=0.000050, Time=41.6s\n",
            "  Epoch 17: Train=28.4529%, Val=36.6095%, LR=0.000050, Time=32.7s\n",
            "  Epoch 18: Train=27.2142%, Val=31.3472%, LR=0.000050, Time=41.7s\n",
            "  Epoch 21: Train=23.7439%, Val=37.8195%, LR=0.000050, Time=32.9s\n",
            "  Epoch 22: Train=22.7201%, Val=30.7314%, LR=0.000050, Time=32.6s\n",
            "  Epoch 23: Train=21.7274%, Val=29.0073%, LR=0.000050, Time=41.4s\n",
            "  Epoch 26: Train=19.0496%, Val=33.3088%, LR=0.000050, Time=32.9s\n",
            "  Epoch 28: Train=17.2892%, Val=25.6562%, LR=0.000050, Time=33.1s\n",
            "  Epoch 29: Train=16.2662%, Val=23.1365%, LR=0.000050, Time=41.7s\n",
            "  Epoch 30: Train=15.3673%, Val=22.0234%, LR=0.000050, Time=41.5s\n",
            "‚úÖ Fold 2 Seed 42 complete: Best Val MAPE = 22.0234% in 19.1min\n",
            "üöÄ Training Fold 2 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=86.4683%, Val=100.3882%, LR=0.000050, Time=41.4s\n",
            "  Epoch  2: Train=70.9350%, Val=83.4071%, LR=0.000050, Time=34.9s\n",
            "  Epoch  3: Train=63.2465%, Val=62.3845%, LR=0.000050, Time=42.3s\n",
            "  Epoch  4: Train=58.6135%, Val=58.7728%, LR=0.000050, Time=42.0s\n",
            "  Epoch  5: Train=55.8105%, Val=54.4553%, LR=0.000050, Time=41.9s\n",
            "  Epoch  6: Train=53.3882%, Val=52.6027%, LR=0.000050, Time=42.8s\n",
            "  Epoch  7: Train=51.3813%, Val=51.1553%, LR=0.000050, Time=41.9s\n",
            "  Epoch  8: Train=49.4983%, Val=49.5366%, LR=0.000050, Time=41.8s\n",
            "  Epoch  9: Train=47.7645%, Val=46.3312%, LR=0.000050, Time=34.3s\n",
            "  Epoch 11: Train=44.3689%, Val=42.1741%, LR=0.000050, Time=37.3s\n",
            "  Epoch 15: Train=38.2339%, Val=41.3959%, LR=0.000050, Time=33.2s\n",
            "  Epoch 16: Train=36.7876%, Val=43.3278%, LR=0.000050, Time=41.7s\n",
            "  Epoch 17: Train=35.3156%, Val=39.6549%, LR=0.000050, Time=33.3s\n",
            "  Epoch 18: Train=33.8280%, Val=39.0301%, LR=0.000050, Time=42.8s\n",
            "  Epoch 19: Train=32.3740%, Val=35.9834%, LR=0.000050, Time=42.3s\n",
            "  Epoch 20: Train=31.0524%, Val=34.9702%, LR=0.000050, Time=42.1s\n",
            "  Epoch 21: Train=29.6793%, Val=30.8875%, LR=0.000050, Time=42.5s\n",
            "  Epoch 26: Train=22.0275%, Val=38.1091%, LR=0.000050, Time=32.9s\n",
            "  Epoch 27: Train=20.3191%, Val=26.5233%, LR=0.000050, Time=33.4s\n",
            "  Epoch 29: Train=17.2206%, Val=23.9240%, LR=0.000050, Time=33.7s\n",
            "‚úÖ Fold 2 Seed 123 complete: Best Val MAPE = 23.9240% in 19.4min\n",
            "üöÄ Training Fold 2 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=74.7630%, Val=95.8200%, LR=0.000050, Time=33.8s\n",
            "  Epoch  2: Train=59.7019%, Val=60.8209%, LR=0.000050, Time=33.4s\n",
            "  Epoch  3: Train=53.3355%, Val=52.2368%, LR=0.000050, Time=41.4s\n",
            "  Epoch  4: Train=49.2493%, Val=48.1396%, LR=0.000050, Time=42.1s\n",
            "  Epoch  5: Train=46.2563%, Val=45.5411%, LR=0.000050, Time=42.0s\n",
            "  Epoch  6: Train=43.9886%, Val=45.2150%, LR=0.000050, Time=42.1s\n",
            "  Epoch  7: Train=42.1192%, Val=44.6513%, LR=0.000050, Time=42.4s\n",
            "  Epoch  8: Train=40.4221%, Val=42.8347%, LR=0.000050, Time=41.8s\n",
            "  Epoch  9: Train=38.8261%, Val=37.2941%, LR=0.000050, Time=41.6s\n",
            "  Epoch 11: Train=35.7737%, Val=42.8849%, LR=0.000050, Time=32.8s\n",
            "  Epoch 14: Train=31.5825%, Val=33.6259%, LR=0.000050, Time=32.7s\n",
            "  Epoch 16: Train=29.1811%, Val=39.8891%, LR=0.000050, Time=33.1s\n",
            "  Epoch 17: Train=27.9530%, Val=30.1902%, LR=0.000050, Time=33.1s\n",
            "  Epoch 18: Train=26.7432%, Val=30.0864%, LR=0.000050, Time=41.7s\n",
            "  Epoch 19: Train=25.5172%, Val=29.4024%, LR=0.000050, Time=41.6s\n",
            "  Epoch 20: Train=24.3596%, Val=28.0513%, LR=0.000050, Time=41.7s\n",
            "  Epoch 21: Train=23.3854%, Val=33.9689%, LR=0.000050, Time=41.8s\n",
            "  Epoch 23: Train=20.8480%, Val=27.1917%, LR=0.000050, Time=32.8s\n",
            "  Epoch 24: Train=19.5915%, Val=22.4171%, LR=0.000050, Time=42.2s\n",
            "  Epoch 26: Train=16.6810%, Val=17.9556%, LR=0.000050, Time=32.8s\n",
            "  Epoch 30: Train=10.5388%, Val=17.0856%, LR=0.000050, Time=33.5s\n",
            "‚úÖ Fold 2 Seed 456 complete: Best Val MAPE = 17.0856% in 19.2min\n",
            "üìà Fold 2 ensemble results:\n",
            "   Mean MAPE: 21.0110% ¬± 2.8821%\n",
            "   Best MAPE: 17.0856%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 57.8 minutes\n",
            "\n",
            "üéØ Training Fold 3 with 3 seeds\n",
            "üöÄ Training Fold 3 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=77.3320%, Val=96.9520%, LR=0.000050, Time=41.2s\n",
            "  Epoch  2: Train=57.3864%, Val=62.1875%, LR=0.000050, Time=34.7s\n",
            "  Epoch  3: Train=50.7806%, Val=49.1152%, LR=0.000050, Time=41.3s\n",
            "  Epoch  4: Train=47.5875%, Val=47.0394%, LR=0.000050, Time=41.6s\n",
            "  Epoch  5: Train=45.3412%, Val=44.0347%, LR=0.000050, Time=42.0s\n",
            "  Epoch  6: Train=43.3216%, Val=42.6390%, LR=0.000050, Time=41.6s\n",
            "  Epoch  7: Train=41.6756%, Val=42.3550%, LR=0.000050, Time=41.6s\n",
            "  Epoch  8: Train=40.1117%, Val=41.6823%, LR=0.000050, Time=41.6s\n",
            "  Epoch 10: Train=37.2654%, Val=40.2058%, LR=0.000050, Time=33.2s\n",
            "  Epoch 11: Train=36.0653%, Val=39.6623%, LR=0.000050, Time=41.8s\n",
            "  Epoch 13: Train=33.5752%, Val=33.4297%, LR=0.000050, Time=33.2s\n",
            "  Epoch 16: Train=29.8472%, Val=39.2977%, LR=0.000050, Time=33.1s\n",
            "  Epoch 19: Train=26.2126%, Val=31.9688%, LR=0.000050, Time=32.9s\n",
            "  Epoch 21: Train=24.0089%, Val=33.4923%, LR=0.000050, Time=32.7s\n",
            "  Epoch 22: Train=22.8087%, Val=31.3839%, LR=0.000050, Time=32.7s\n",
            "  Epoch 24: Train=20.6678%, Val=28.1876%, LR=0.000050, Time=32.9s\n",
            "  Epoch 26: Train=18.7353%, Val=28.6673%, LR=0.000050, Time=33.0s\n",
            "  Epoch 27: Train=17.7093%, Val=24.0431%, LR=0.000050, Time=32.9s\n",
            "  Epoch 28: Train=16.7799%, Val=20.7074%, LR=0.000050, Time=41.4s\n",
            "‚úÖ Fold 3 Seed 42 complete: Best Val MAPE = 20.7074% in 19.1min\n",
            "üöÄ Training Fold 3 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=86.4658%, Val=101.1321%, LR=0.000050, Time=32.6s\n",
            "  Epoch  2: Train=70.9488%, Val=82.8853%, LR=0.000050, Time=34.6s\n",
            "  Epoch  3: Train=63.5576%, Val=61.5420%, LR=0.000050, Time=41.8s\n",
            "  Epoch  4: Train=58.7890%, Val=58.4002%, LR=0.000050, Time=41.8s\n",
            "  Epoch  5: Train=55.8479%, Val=55.3164%, LR=0.000050, Time=42.0s\n",
            "  Epoch  6: Train=53.5494%, Val=57.0519%, LR=0.000050, Time=40.9s\n",
            "  Epoch  8: Train=49.7303%, Val=48.6440%, LR=0.000050, Time=32.6s\n",
            "  Epoch  9: Train=48.0501%, Val=48.3377%, LR=0.000050, Time=41.1s\n",
            "  Epoch 10: Train=46.4339%, Val=41.9342%, LR=0.000050, Time=41.2s\n",
            "  Epoch 11: Train=44.8304%, Val=43.5654%, LR=0.000050, Time=41.3s\n",
            "  Epoch 13: Train=41.7794%, Val=39.3694%, LR=0.000050, Time=33.1s\n",
            "  Epoch 15: Train=38.6632%, Val=30.6933%, LR=0.000050, Time=32.8s\n",
            "  Epoch 16: Train=37.3020%, Val=40.3281%, LR=0.000050, Time=41.4s\n",
            "  Epoch 21: Train=29.9022%, Val=31.9778%, LR=0.000025, Time=32.4s\n",
            "    üìâ Learning rate reduced: 5.00e-05 ‚Üí 2.50e-05\n",
            "    ‚èπÔ∏è  Early stopping at epoch 23\n",
            "‚úÖ Fold 3 Seed 123 complete: Best Val MAPE = 30.6933% in 14.1min\n",
            "üöÄ Training Fold 3 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=74.7820%, Val=95.1648%, LR=0.000050, Time=32.8s\n",
            "  Epoch  2: Train=59.6660%, Val=57.4404%, LR=0.000050, Time=32.9s\n",
            "  Epoch  3: Train=53.3456%, Val=50.1547%, LR=0.000050, Time=41.8s\n",
            "  Epoch  4: Train=49.2979%, Val=46.6725%, LR=0.000050, Time=41.2s\n",
            "  Epoch  5: Train=46.2376%, Val=46.3959%, LR=0.000050, Time=41.8s\n",
            "  Epoch  6: Train=43.9096%, Val=42.5527%, LR=0.000050, Time=41.5s\n",
            "  Epoch  9: Train=38.6608%, Val=42.3545%, LR=0.000050, Time=33.0s\n",
            "  Epoch 10: Train=37.1283%, Val=41.6484%, LR=0.000050, Time=41.6s\n",
            "  Epoch 11: Train=35.6180%, Val=40.4343%, LR=0.000050, Time=41.9s\n",
            "  Epoch 13: Train=32.8427%, Val=40.2217%, LR=0.000050, Time=33.2s\n",
            "  Epoch 14: Train=31.4886%, Val=30.8736%, LR=0.000050, Time=41.7s\n",
            "  Epoch 16: Train=28.7894%, Val=37.5433%, LR=0.000050, Time=33.4s\n",
            "  Epoch 18: Train=26.4234%, Val=29.2237%, LR=0.000050, Time=32.6s\n",
            "  Epoch 21: Train=22.4319%, Val=37.9888%, LR=0.000050, Time=32.7s\n",
            "  Epoch 22: Train=21.1488%, Val=23.3166%, LR=0.000050, Time=32.7s\n",
            "  Epoch 26: Train=16.6490%, Val=34.5409%, LR=0.000050, Time=32.6s\n",
            "  Epoch 27: Train=15.4350%, Val=21.0406%, LR=0.000050, Time=32.5s\n",
            "  Epoch 28: Train=14.2489%, Val=18.3141%, LR=0.000050, Time=42.0s\n",
            "  Epoch 30: Train=11.9106%, Val=17.5785%, LR=0.000050, Time=32.0s\n",
            "‚úÖ Fold 3 Seed 456 complete: Best Val MAPE = 17.5785% in 18.7min\n",
            "üìà Fold 3 ensemble results:\n",
            "   Mean MAPE: 22.9930% ¬± 5.5927%\n",
            "   Best MAPE: 17.5785%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 52.0 minutes\n",
            "\n",
            "üéØ Training Fold 4 with 3 seeds\n",
            "üöÄ Training Fold 4 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=77.4268%, Val=95.8948%, LR=0.000050, Time=41.0s\n",
            "  Epoch  2: Train=57.4740%, Val=54.2705%, LR=0.000050, Time=33.3s\n",
            "  Epoch  3: Train=50.6213%, Val=48.1241%, LR=0.000050, Time=41.8s\n",
            "  Epoch  4: Train=47.5297%, Val=46.0064%, LR=0.000050, Time=41.8s\n",
            "  Epoch  6: Train=43.4119%, Val=42.9962%, LR=0.000050, Time=32.4s\n",
            "  Epoch  7: Train=41.7982%, Val=42.7092%, LR=0.000050, Time=41.7s\n",
            "  Epoch  8: Train=40.2158%, Val=42.5807%, LR=0.000050, Time=41.5s\n",
            "  Epoch  9: Train=38.8007%, Val=42.1308%, LR=0.000050, Time=41.7s\n",
            "  Epoch 10: Train=37.2095%, Val=40.7575%, LR=0.000050, Time=41.8s\n",
            "  Epoch 11: Train=35.8809%, Val=40.0420%, LR=0.000050, Time=41.7s\n",
            "  Epoch 13: Train=33.2453%, Val=39.3645%, LR=0.000050, Time=32.8s\n",
            "  Epoch 14: Train=31.9769%, Val=39.3645%, LR=0.000050, Time=41.3s\n",
            "  Epoch 16: Train=29.3216%, Val=39.1503%, LR=0.000050, Time=32.9s\n",
            "  Epoch 17: Train=28.1106%, Val=38.6965%, LR=0.000050, Time=41.8s\n",
            "  Epoch 18: Train=26.9309%, Val=37.1189%, LR=0.000050, Time=41.9s\n",
            "  Epoch 19: Train=25.7328%, Val=37.0884%, LR=0.000050, Time=41.8s\n",
            "  Epoch 20: Train=24.5487%, Val=36.2658%, LR=0.000050, Time=41.2s\n",
            "  Epoch 21: Train=23.4715%, Val=35.4761%, LR=0.000050, Time=41.5s\n",
            "  Epoch 22: Train=22.3707%, Val=31.6704%, LR=0.000050, Time=41.6s\n",
            "  Epoch 26: Train=18.0470%, Val=33.3529%, LR=0.000050, Time=32.8s\n",
            "  Epoch 28: Train=16.2143%, Val=25.5122%, LR=0.000050, Time=32.4s\n",
            "  Epoch 30: Train=14.3940%, Val=14.1874%, LR=0.000050, Time=32.7s\n",
            "‚úÖ Fold 4 Seed 42 complete: Best Val MAPE = 14.1874% in 19.7min\n",
            "üöÄ Training Fold 4 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=86.5121%, Val=100.3992%, LR=0.000050, Time=41.1s\n",
            "  Epoch  2: Train=70.8488%, Val=82.0801%, LR=0.000050, Time=32.8s\n",
            "  Epoch  3: Train=63.2819%, Val=62.1014%, LR=0.000050, Time=41.8s\n",
            "  Epoch  4: Train=58.7399%, Val=59.7611%, LR=0.000050, Time=41.7s\n",
            "  Epoch  5: Train=55.8793%, Val=54.1104%, LR=0.000050, Time=42.1s\n",
            "  Epoch  6: Train=53.5836%, Val=55.1217%, LR=0.000050, Time=42.0s\n",
            "  Epoch  7: Train=51.5715%, Val=53.9258%, LR=0.000050, Time=32.7s\n",
            "  Epoch  8: Train=49.7631%, Val=52.3458%, LR=0.000050, Time=41.6s\n",
            "  Epoch  9: Train=48.0817%, Val=51.7647%, LR=0.000050, Time=41.6s\n",
            "  Epoch 10: Train=46.4835%, Val=50.1712%, LR=0.000050, Time=41.7s\n",
            "  Epoch 11: Train=44.9503%, Val=44.4888%, LR=0.000050, Time=41.9s\n",
            "  Epoch 12: Train=43.3084%, Val=41.4460%, LR=0.000050, Time=41.9s\n",
            "  Epoch 13: Train=41.6392%, Val=40.9281%, LR=0.000050, Time=41.5s\n",
            "  Epoch 15: Train=38.7252%, Val=39.9906%, LR=0.000050, Time=32.5s\n",
            "  Epoch 16: Train=37.2852%, Val=42.3827%, LR=0.000050, Time=41.1s\n",
            "  Epoch 18: Train=34.2320%, Val=37.3303%, LR=0.000050, Time=32.6s\n",
            "  Epoch 21: Train=29.8749%, Val=38.7104%, LR=0.000050, Time=32.8s\n",
            "  Epoch 22: Train=28.3254%, Val=35.5710%, LR=0.000050, Time=32.6s\n",
            "  Epoch 26: Train=22.0306%, Val=28.0966%, LR=0.000050, Time=33.1s\n",
            "  Epoch 29: Train=17.1196%, Val=23.0023%, LR=0.000050, Time=32.3s\n",
            "‚úÖ Fold 4 Seed 123 complete: Best Val MAPE = 23.0023% in 19.2min\n",
            "üöÄ Training Fold 4 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=74.7939%, Val=95.9650%, LR=0.000050, Time=32.9s\n",
            "  Epoch  2: Train=59.7549%, Val=65.5569%, LR=0.000050, Time=34.0s\n",
            "  Epoch  3: Train=53.2804%, Val=51.4861%, LR=0.000050, Time=42.1s\n",
            "  Epoch  4: Train=49.1877%, Val=47.6007%, LR=0.000050, Time=41.7s\n",
            "  Epoch  5: Train=46.1275%, Val=45.9482%, LR=0.000050, Time=41.0s\n",
            "  Epoch  6: Train=43.8193%, Val=43.3585%, LR=0.000050, Time=41.5s\n",
            "  Epoch  8: Train=40.2298%, Val=43.1222%, LR=0.000050, Time=33.0s\n",
            "  Epoch  9: Train=38.5558%, Val=41.7999%, LR=0.000050, Time=41.2s\n",
            "  Epoch 10: Train=36.9985%, Val=41.2804%, LR=0.000050, Time=41.6s\n",
            "  Epoch 11: Train=35.4996%, Val=39.3298%, LR=0.000050, Time=41.7s\n",
            "  Epoch 12: Train=34.1423%, Val=36.3315%, LR=0.000050, Time=41.8s\n",
            "  Epoch 16: Train=28.8452%, Val=30.8080%, LR=0.000050, Time=32.8s\n",
            "  Epoch 18: Train=26.3933%, Val=30.1027%, LR=0.000050, Time=32.5s\n",
            "  Epoch 21: Train=22.6611%, Val=24.5131%, LR=0.000050, Time=32.4s\n",
            "  Epoch 25: Train=17.7622%, Val=23.3903%, LR=0.000050, Time=33.0s\n",
            "  Epoch 26: Train=16.6323%, Val=37.3615%, LR=0.000050, Time=41.3s\n",
            "  Epoch 28: Train=14.2589%, Val=19.8182%, LR=0.000050, Time=32.6s\n",
            "‚úÖ Fold 4 Seed 456 complete: Best Val MAPE = 19.8182% in 18.9min\n",
            "üìà Fold 4 ensemble results:\n",
            "   Mean MAPE: 19.0027% ¬± 3.6446%\n",
            "   Best MAPE: 14.1874%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 57.8 minutes\n",
            "\n",
            "============================================================\n",
            "üìä COMPREHENSIVE ENSEMBLE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "üìã Individual Fold Analysis:\n",
            "Fold   Best     Mean     Std      Seeds       \n",
            "--------------------------------------------------\n",
            "0      16.3603  22.4418  4.4253   3           \n",
            "1      19.5369  25.0280  7.3718   3           \n",
            "2      17.0856  21.0110  2.8821   3           \n",
            "3      17.5785  22.9930  5.5927   3           \n",
            "4      14.1874  19.0027  3.6446   3           \n",
            "\n",
            "üéØ Overall Performance Summary:\n",
            "   Total models trained: 15\n",
            "   Overall mean MAPE: 22.0953% ¬± 5.4233%\n",
            "   Best single model: 14.1874%\n",
            "   Expected ensemble MAPE: 22.0953%\n",
            "   Total training time: 5.03 hours\n",
            "   Average time per model: 20.1 minutes\n",
            "\n",
            "üìà Performance Analysis:\n",
            "   Best single fold performance: 14.1874%\n",
            "   Mean of best fold performances: 16.9497%\n",
            "   Stability improvement: 5.4233% standard deviation\n",
            "\n",
            "üèÜ Competition Analysis:\n",
            "   Models below 3.0% target: 0/15\n",
            "   Success rate: 0.0%\n",
            "   üéØ Gap to target: 11.1874%\n",
            "üíæ Results saved to:\n",
            "   /content/drive/MyDrive/ThinkOnward/Result/Phase2c/ensemble_results.json\n",
            "   /content/drive/MyDrive/ThinkOnward/Result/Phase2c/training_summary.txt\n",
            "\n",
            "‚úÖ Phase 2c Training Complete!\n",
            "Ready for diffusion model development in Phase 3\n"
          ]
        }
      ],
      "source": [
        "# Run the optimized training for original Unet\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimized training for StabilizedUnet\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vafjc7WqztxY",
        "outputId": "a4e43665-9caa-45be-9367-d6a1f2141059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Phase 2c Optimized Training Pipeline\n",
            "   Target: Sub-3.0% MAPE with stable ensemble\n",
            "   Strategy: 5 folds √ó 3 seeds = 15 models\n",
            "   Hardware: A100 GPU with batch_size=32\n",
            "üéØ Multi-Seed Trainer initialized\n",
            "   Data: /content/drive/MyDrive/ThinkOnward/Data/Train\n",
            "   Results: /content/drive/MyDrive/ThinkOnward/Result/Phase2c\n",
            "   Seeds: [42, 123, 456]\n",
            "   Total models to train: 15\n",
            "\n",
            "============================================================\n",
            "üöÄ STARTING OPTIMIZED MULTI-SEED ENSEMBLE TRAINING\n",
            "============================================================\n",
            "üìä Created 5-fold splits\n",
            "\n",
            "üéØ Training Fold 0 with 3 seeds\n",
            "üöÄ Training Fold 0 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-46e5a01bdf9d>:19: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:217.)\n",
            "  attention = torch.bmm(query, key)\n",
            "<ipython-input-15-46e5a01bdf9d>:22: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:217.)\n",
            "  out = torch.bmm(value, attention.permute(0, 2, 1))\n",
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:217.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch  1: Train=136.7605%, Val=38.4531%, LR=0.000050, Time=5513.2s\n",
            "  Epoch  2: Train=41.3112%, Val=20.9334%, LR=0.000050, Time=36.0s\n",
            "  Epoch  3: Train=23.9276%, Val=12.8215%, LR=0.000050, Time=43.9s\n",
            "  Epoch  4: Train=18.3436%, Val=9.6654%, LR=0.000050, Time=44.7s\n",
            "  Epoch  5: Train=15.4221%, Val=8.7806%, LR=0.000050, Time=43.6s\n",
            "  Epoch  6: Train=13.5812%, Val=7.9705%, LR=0.000050, Time=43.6s\n",
            "  Epoch  7: Train=12.3909%, Val=7.6224%, LR=0.000050, Time=44.9s\n",
            "  Epoch  8: Train=11.5377%, Val=6.9995%, LR=0.000050, Time=44.1s\n",
            "  Epoch  9: Train=10.8307%, Val=6.8610%, LR=0.000050, Time=44.4s\n",
            "  Epoch 10: Train=10.1804%, Val=6.3582%, LR=0.000050, Time=43.9s\n",
            "  Epoch 11: Train=9.8002%, Val=6.1080%, LR=0.000050, Time=44.4s\n",
            "  Epoch 12: Train=9.3976%, Val=5.6898%, LR=0.000050, Time=44.7s\n",
            "  Epoch 13: Train=8.8665%, Val=5.5334%, LR=0.000050, Time=44.2s\n",
            "  Epoch 14: Train=8.4973%, Val=5.4660%, LR=0.000050, Time=44.5s\n",
            "  Epoch 16: Train=8.0429%, Val=4.9705%, LR=0.000050, Time=34.9s\n",
            "  Epoch 18: Train=7.5495%, Val=4.9169%, LR=0.000050, Time=34.8s\n",
            "  Epoch 19: Train=7.3331%, Val=4.7393%, LR=0.000050, Time=42.9s\n",
            "  Epoch 21: Train=7.1474%, Val=4.7796%, LR=0.000050, Time=33.6s\n",
            "  Epoch 22: Train=6.9130%, Val=4.7251%, LR=0.000050, Time=34.0s\n",
            "  Epoch 23: Train=6.8218%, Val=4.7062%, LR=0.000050, Time=43.4s\n",
            "  Epoch 24: Train=6.7167%, Val=4.5826%, LR=0.000050, Time=44.0s\n",
            "  Epoch 26: Train=6.4576%, Val=4.3623%, LR=0.000050, Time=35.3s\n",
            "  Epoch 29: Train=6.2017%, Val=4.2638%, LR=0.000050, Time=36.0s\n",
            "‚úÖ Fold 0 Seed 42 complete: Best Val MAPE = 4.2638% in 112.4min\n",
            "üöÄ Training Fold 0 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=94.9706%, Val=34.6421%, LR=0.000050, Time=34.8s\n",
            "  Epoch  2: Train=37.8804%, Val=16.8341%, LR=0.000050, Time=36.0s\n",
            "  Epoch  3: Train=24.3809%, Val=13.2016%, LR=0.000050, Time=43.4s\n",
            "  Epoch  4: Train=18.6181%, Val=11.6827%, LR=0.000050, Time=43.3s\n",
            "  Epoch  5: Train=15.6834%, Val=9.9341%, LR=0.000050, Time=43.1s\n",
            "  Epoch  6: Train=13.8176%, Val=9.0770%, LR=0.000050, Time=43.6s\n",
            "  Epoch  7: Train=12.6241%, Val=8.5679%, LR=0.000050, Time=43.5s\n",
            "  Epoch  8: Train=11.7064%, Val=7.4580%, LR=0.000050, Time=43.5s\n",
            "  Epoch  9: Train=11.2051%, Val=7.3378%, LR=0.000050, Time=44.0s\n",
            "  Epoch 10: Train=10.6519%, Val=7.2659%, LR=0.000050, Time=43.3s\n",
            "  Epoch 11: Train=10.0384%, Val=7.2320%, LR=0.000050, Time=43.7s\n",
            "  Epoch 12: Train=9.4242%, Val=6.7715%, LR=0.000050, Time=44.3s\n",
            "  Epoch 13: Train=8.9680%, Val=6.1526%, LR=0.000050, Time=44.4s\n",
            "  Epoch 16: Train=8.1394%, Val=6.0524%, LR=0.000050, Time=34.8s\n",
            "  Epoch 18: Train=7.6701%, Val=5.5759%, LR=0.000050, Time=34.6s\n",
            "  Epoch 21: Train=7.1342%, Val=5.4120%, LR=0.000050, Time=34.4s\n",
            "  Epoch 26: Train=6.7330%, Val=4.9911%, LR=0.000050, Time=34.2s\n",
            "  Epoch 28: Train=6.4847%, Val=4.7760%, LR=0.000050, Time=35.2s\n",
            "‚úÖ Fold 0 Seed 123 complete: Best Val MAPE = 4.7760% in 20.2min\n",
            "üöÄ Training Fold 0 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=117.1529%, Val=33.1309%, LR=0.000050, Time=35.2s\n",
            "  Epoch  2: Train=42.3382%, Val=18.9348%, LR=0.000050, Time=36.6s\n",
            "  Epoch  3: Train=25.1562%, Val=12.1165%, LR=0.000050, Time=44.4s\n",
            "  Epoch  4: Train=18.7955%, Val=10.3983%, LR=0.000050, Time=43.9s\n",
            "  Epoch  5: Train=15.7553%, Val=8.6544%, LR=0.000050, Time=43.8s\n",
            "  Epoch  6: Train=13.9331%, Val=8.6387%, LR=0.000050, Time=44.4s\n",
            "  Epoch  7: Train=12.9251%, Val=7.5223%, LR=0.000050, Time=44.1s\n",
            "  Epoch  9: Train=11.2267%, Val=6.8181%, LR=0.000050, Time=35.1s\n",
            "  Epoch 10: Train=10.5887%, Val=6.2890%, LR=0.000050, Time=44.0s\n",
            "  Epoch 11: Train=10.1078%, Val=6.4419%, LR=0.000050, Time=44.0s\n",
            "  Epoch 13: Train=9.2823%, Val=6.0588%, LR=0.000050, Time=35.4s\n",
            "  Epoch 14: Train=8.7628%, Val=5.4144%, LR=0.000050, Time=44.5s\n",
            "  Epoch 16: Train=8.1603%, Val=5.3623%, LR=0.000050, Time=35.8s\n",
            "  Epoch 18: Train=7.7015%, Val=4.8230%, LR=0.000050, Time=35.3s\n",
            "  Epoch 21: Train=7.2212%, Val=4.6496%, LR=0.000050, Time=34.9s\n",
            "  Epoch 22: Train=7.1075%, Val=4.6478%, LR=0.000050, Time=44.6s\n",
            "  Epoch 24: Train=6.8394%, Val=4.5597%, LR=0.000050, Time=35.4s\n",
            "  Epoch 25: Train=6.7081%, Val=4.5343%, LR=0.000050, Time=44.1s\n",
            "  Epoch 26: Train=6.7748%, Val=5.4794%, LR=0.000050, Time=44.3s\n",
            "  Epoch 27: Train=6.6120%, Val=4.5206%, LR=0.000050, Time=34.4s\n",
            "  Epoch 28: Train=6.5126%, Val=4.4640%, LR=0.000050, Time=42.8s\n",
            "  Epoch 29: Train=6.3136%, Val=4.3590%, LR=0.000050, Time=42.9s\n",
            "  Epoch 30: Train=6.2264%, Val=4.2916%, LR=0.000050, Time=43.5s\n",
            "‚úÖ Fold 0 Seed 456 complete: Best Val MAPE = 4.2916% in 20.8min\n",
            "üìà Fold 0 ensemble results:\n",
            "   Mean MAPE: 4.4438% ¬± 0.2352%\n",
            "   Best MAPE: 4.2638%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 153.4 minutes\n",
            "\n",
            "üéØ Training Fold 1 with 3 seeds\n",
            "üöÄ Training Fold 1 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=136.8001%, Val=38.7599%, LR=0.000050, Time=43.9s\n",
            "  Epoch  2: Train=41.2641%, Val=20.0442%, LR=0.000050, Time=36.5s\n",
            "  Epoch  3: Train=23.5929%, Val=13.2470%, LR=0.000050, Time=44.1s\n",
            "  Epoch  4: Train=17.9279%, Val=8.9595%, LR=0.000050, Time=43.3s\n",
            "  Epoch  5: Train=15.3356%, Val=8.5139%, LR=0.000050, Time=44.1s\n",
            "  Epoch  6: Train=13.4816%, Val=7.5116%, LR=0.000050, Time=44.6s\n",
            "  Epoch  8: Train=11.4483%, Val=6.6552%, LR=0.000050, Time=35.2s\n",
            "  Epoch  9: Train=10.7308%, Val=6.3847%, LR=0.000050, Time=44.1s\n",
            "  Epoch 10: Train=10.2595%, Val=6.0797%, LR=0.000050, Time=44.4s\n",
            "  Epoch 11: Train=9.6414%, Val=5.8021%, LR=0.000050, Time=44.1s\n",
            "  Epoch 12: Train=9.1807%, Val=5.5219%, LR=0.000050, Time=44.2s\n",
            "  Epoch 15: Train=8.2904%, Val=5.0378%, LR=0.000050, Time=35.0s\n",
            "  Epoch 16: Train=7.9610%, Val=4.8871%, LR=0.000050, Time=44.0s\n",
            "  Epoch 21: Train=7.0905%, Val=4.9339%, LR=0.000050, Time=35.0s\n",
            "  Epoch 22: Train=6.9223%, Val=4.3905%, LR=0.000050, Time=34.8s\n",
            "  Epoch 26: Train=6.4962%, Val=4.3967%, LR=0.000050, Time=34.8s\n",
            "  Epoch 27: Train=6.3816%, Val=4.3119%, LR=0.000050, Time=34.9s\n",
            "  Epoch 29: Train=6.3129%, Val=4.2209%, LR=0.000050, Time=34.8s\n",
            "‚úÖ Fold 1 Seed 42 complete: Best Val MAPE = 4.2209% in 20.2min\n",
            "üöÄ Training Fold 1 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=94.9427%, Val=35.1734%, LR=0.000050, Time=35.4s\n",
            "  Epoch  2: Train=38.5318%, Val=17.3632%, LR=0.000050, Time=36.9s\n",
            "  Epoch  3: Train=24.6811%, Val=12.3036%, LR=0.000050, Time=44.0s\n",
            "  Epoch  4: Train=18.6411%, Val=11.2797%, LR=0.000050, Time=44.5s\n",
            "  Epoch  5: Train=15.5084%, Val=10.3217%, LR=0.000050, Time=44.3s\n",
            "  Epoch  6: Train=13.9489%, Val=8.5953%, LR=0.000050, Time=44.4s\n",
            "  Epoch  7: Train=12.6860%, Val=7.5893%, LR=0.000050, Time=43.5s\n",
            "  Epoch  9: Train=11.2452%, Val=7.0432%, LR=0.000050, Time=33.7s\n",
            "  Epoch 11: Train=10.1026%, Val=7.0581%, LR=0.000050, Time=34.5s\n",
            "  Epoch 12: Train=9.4163%, Val=6.0622%, LR=0.000050, Time=33.8s\n",
            "  Epoch 13: Train=9.0299%, Val=5.9274%, LR=0.000050, Time=44.6s\n",
            "  Epoch 14: Train=8.7041%, Val=5.9267%, LR=0.000050, Time=44.3s\n",
            "  Epoch 15: Train=8.3285%, Val=5.6541%, LR=0.000050, Time=44.2s\n",
            "  Epoch 16: Train=8.1478%, Val=5.4668%, LR=0.000050, Time=44.4s\n",
            "  Epoch 20: Train=7.3379%, Val=5.2901%, LR=0.000050, Time=34.0s\n",
            "  Epoch 21: Train=7.2152%, Val=5.0603%, LR=0.000050, Time=42.9s\n",
            "  Epoch 26: Train=6.7402%, Val=4.6761%, LR=0.000050, Time=33.8s\n",
            "‚úÖ Fold 1 Seed 123 complete: Best Val MAPE = 4.6761% in 19.7min\n",
            "üöÄ Training Fold 1 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=117.1931%, Val=33.4798%, LR=0.000050, Time=33.8s\n",
            "  Epoch  2: Train=42.3424%, Val=19.4971%, LR=0.000050, Time=34.6s\n",
            "  Epoch  3: Train=25.1429%, Val=12.6722%, LR=0.000050, Time=42.5s\n",
            "  Epoch  4: Train=18.9029%, Val=10.6844%, LR=0.000050, Time=42.4s\n",
            "  Epoch  5: Train=15.8162%, Val=8.9873%, LR=0.000050, Time=42.5s\n",
            "  Epoch  6: Train=13.8338%, Val=7.7815%, LR=0.000050, Time=42.2s\n",
            "  Epoch  7: Train=12.6298%, Val=7.0583%, LR=0.000050, Time=42.3s\n",
            "  Epoch  9: Train=11.1925%, Val=6.6564%, LR=0.000050, Time=34.2s\n",
            "  Epoch 10: Train=10.6320%, Val=6.3244%, LR=0.000050, Time=42.4s\n",
            "  Epoch 11: Train=10.1429%, Val=6.1388%, LR=0.000050, Time=43.2s\n",
            "  Epoch 12: Train=9.6567%, Val=5.9261%, LR=0.000050, Time=42.3s\n",
            "  Epoch 14: Train=8.8356%, Val=5.2753%, LR=0.000050, Time=33.5s\n",
            "  Epoch 16: Train=8.3106%, Val=4.9551%, LR=0.000050, Time=34.1s\n",
            "  Epoch 18: Train=7.8181%, Val=4.8223%, LR=0.000050, Time=34.6s\n",
            "  Epoch 19: Train=7.6448%, Val=4.7549%, LR=0.000050, Time=42.5s\n",
            "  Epoch 21: Train=7.2736%, Val=4.5872%, LR=0.000050, Time=34.1s\n",
            "  Epoch 26: Train=6.8651%, Val=4.9572%, LR=0.000050, Time=33.6s\n",
            "  Epoch 27: Train=6.5360%, Val=4.3789%, LR=0.000050, Time=33.3s\n",
            "  Epoch 29: Train=6.3684%, Val=4.3207%, LR=0.000050, Time=33.7s\n",
            "  Epoch 30: Train=6.1972%, Val=4.2291%, LR=0.000050, Time=42.8s\n",
            "‚úÖ Fold 1 Seed 456 complete: Best Val MAPE = 4.2291% in 19.7min\n",
            "üìà Fold 1 ensemble results:\n",
            "   Mean MAPE: 4.3754% ¬± 0.2127%\n",
            "   Best MAPE: 4.2209%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 59.8 minutes\n",
            "\n",
            "üéØ Training Fold 2 with 3 seeds\n",
            "üöÄ Training Fold 2 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=136.8271%, Val=39.0487%, LR=0.000050, Time=42.0s\n",
            "  Epoch  2: Train=41.6393%, Val=20.0385%, LR=0.000050, Time=35.6s\n",
            "  Epoch  3: Train=24.2989%, Val=14.1339%, LR=0.000050, Time=42.6s\n",
            "  Epoch  4: Train=18.1703%, Val=9.7336%, LR=0.000050, Time=42.3s\n",
            "  Epoch  5: Train=15.0508%, Val=8.8540%, LR=0.000050, Time=42.6s\n",
            "  Epoch  6: Train=13.1492%, Val=7.3687%, LR=0.000050, Time=42.8s\n",
            "  Epoch  8: Train=11.4012%, Val=7.2679%, LR=0.000050, Time=34.1s\n",
            "  Epoch  9: Train=10.7602%, Val=6.8381%, LR=0.000050, Time=42.5s\n",
            "  Epoch 10: Train=10.1955%, Val=6.3975%, LR=0.000050, Time=42.5s\n",
            "  Epoch 11: Train=9.5428%, Val=6.0630%, LR=0.000050, Time=42.3s\n",
            "  Epoch 12: Train=9.0915%, Val=5.5484%, LR=0.000050, Time=42.4s\n",
            "  Epoch 13: Train=8.6271%, Val=5.5390%, LR=0.000050, Time=42.2s\n",
            "  Epoch 14: Train=8.3366%, Val=5.2920%, LR=0.000050, Time=42.7s\n",
            "  Epoch 15: Train=8.0369%, Val=5.0887%, LR=0.000050, Time=42.9s\n",
            "  Epoch 16: Train=7.8071%, Val=5.0213%, LR=0.000050, Time=43.0s\n",
            "  Epoch 17: Train=7.7100%, Val=5.0118%, LR=0.000050, Time=42.6s\n",
            "  Epoch 18: Train=7.4937%, Val=4.9043%, LR=0.000050, Time=42.5s\n",
            "  Epoch 20: Train=7.0705%, Val=4.8180%, LR=0.000050, Time=33.8s\n",
            "  Epoch 21: Train=7.0178%, Val=4.9030%, LR=0.000050, Time=42.2s\n",
            "  Epoch 22: Train=6.7580%, Val=4.4854%, LR=0.000050, Time=33.4s\n",
            "  Epoch 26: Train=6.4120%, Val=4.3165%, LR=0.000050, Time=33.7s\n",
            "  Epoch 29: Train=6.2702%, Val=4.2856%, LR=0.000050, Time=33.5s\n",
            "‚úÖ Fold 2 Seed 42 complete: Best Val MAPE = 4.2856% in 20.3min\n",
            "üöÄ Training Fold 2 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=94.8129%, Val=35.0609%, LR=0.000050, Time=33.3s\n",
            "  Epoch  2: Train=38.2734%, Val=17.3488%, LR=0.000050, Time=32.9s\n",
            "  Epoch  3: Train=24.8408%, Val=13.4450%, LR=0.000050, Time=41.8s\n",
            "  Epoch  4: Train=18.6219%, Val=10.8849%, LR=0.000050, Time=42.0s\n",
            "  Epoch  5: Train=15.6244%, Val=10.0681%, LR=0.000050, Time=42.1s\n",
            "  Epoch  6: Train=13.7466%, Val=8.6201%, LR=0.000050, Time=41.9s\n",
            "  Epoch  7: Train=12.5324%, Val=7.7380%, LR=0.000050, Time=42.2s\n",
            "  Epoch  9: Train=11.0458%, Val=7.1756%, LR=0.000050, Time=33.5s\n",
            "  Epoch 10: Train=10.4560%, Val=7.1214%, LR=0.000050, Time=42.5s\n",
            "  Epoch 11: Train=9.8157%, Val=7.2286%, LR=0.000050, Time=42.1s\n",
            "  Epoch 12: Train=9.2967%, Val=6.0814%, LR=0.000050, Time=32.8s\n",
            "  Epoch 15: Train=8.2757%, Val=5.9133%, LR=0.000050, Time=33.7s\n",
            "  Epoch 16: Train=8.0080%, Val=5.3538%, LR=0.000050, Time=42.2s\n",
            "  Epoch 20: Train=7.3013%, Val=5.1110%, LR=0.000050, Time=34.0s\n",
            "  Epoch 21: Train=7.0913%, Val=5.0237%, LR=0.000050, Time=42.1s\n",
            "  Epoch 26: Train=6.6290%, Val=5.0021%, LR=0.000050, Time=33.6s\n",
            "  Epoch 27: Train=6.4397%, Val=4.6757%, LR=0.000050, Time=42.0s\n",
            "  Epoch 28: Train=6.4807%, Val=4.4337%, LR=0.000050, Time=41.9s\n",
            "‚úÖ Fold 2 Seed 123 complete: Best Val MAPE = 4.4337% in 19.3min\n",
            "üöÄ Training Fold 2 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=117.1945%, Val=33.4586%, LR=0.000050, Time=32.9s\n",
            "  Epoch  2: Train=42.3038%, Val=18.7524%, LR=0.000050, Time=34.5s\n",
            "  Epoch  3: Train=25.1501%, Val=14.3893%, LR=0.000050, Time=42.0s\n",
            "  Epoch  4: Train=19.1094%, Val=10.6259%, LR=0.000050, Time=41.9s\n",
            "  Epoch  5: Train=15.7719%, Val=9.1614%, LR=0.000050, Time=42.3s\n",
            "  Epoch  6: Train=13.8040%, Val=8.1392%, LR=0.000050, Time=42.2s\n",
            "  Epoch  7: Train=12.7302%, Val=7.2959%, LR=0.000050, Time=42.6s\n",
            "  Epoch  9: Train=11.0280%, Val=6.6820%, LR=0.000050, Time=34.5s\n",
            "  Epoch 10: Train=10.5203%, Val=6.3138%, LR=0.000050, Time=42.5s\n",
            "  Epoch 11: Train=10.0137%, Val=6.2011%, LR=0.000050, Time=42.2s\n",
            "  Epoch 13: Train=9.2847%, Val=5.8276%, LR=0.000050, Time=33.6s\n",
            "  Epoch 14: Train=8.6949%, Val=5.4200%, LR=0.000050, Time=42.8s\n",
            "  Epoch 16: Train=8.0751%, Val=5.0529%, LR=0.000050, Time=33.3s\n",
            "  Epoch 18: Train=7.6853%, Val=4.8403%, LR=0.000050, Time=33.2s\n",
            "  Epoch 21: Train=7.2406%, Val=4.6283%, LR=0.000050, Time=33.7s\n",
            "  Epoch 23: Train=6.9024%, Val=4.5918%, LR=0.000050, Time=33.9s\n",
            "  Epoch 25: Train=6.6538%, Val=4.4252%, LR=0.000050, Time=33.6s\n",
            "  Epoch 26: Train=6.7147%, Val=4.8215%, LR=0.000050, Time=42.5s\n",
            "  Epoch 29: Train=6.4951%, Val=4.3163%, LR=0.000050, Time=33.4s\n",
            "‚úÖ Fold 2 Seed 456 complete: Best Val MAPE = 4.3163% in 19.6min\n",
            "üìà Fold 2 ensemble results:\n",
            "   Mean MAPE: 4.3452% ¬± 0.0638%\n",
            "   Best MAPE: 4.2856%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 59.3 minutes\n",
            "\n",
            "üéØ Training Fold 3 with 3 seeds\n",
            "üöÄ Training Fold 3 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=136.6250%, Val=38.9199%, LR=0.000050, Time=34.0s\n",
            "  Epoch  2: Train=40.9699%, Val=19.6726%, LR=0.000050, Time=34.9s\n",
            "  Epoch  3: Train=23.5678%, Val=13.5415%, LR=0.000050, Time=42.4s\n",
            "  Epoch  4: Train=17.8754%, Val=11.2863%, LR=0.000050, Time=42.7s\n",
            "  Epoch  5: Train=14.9092%, Val=8.9343%, LR=0.000050, Time=42.9s\n",
            "  Epoch  6: Train=13.1347%, Val=8.3445%, LR=0.000050, Time=42.9s\n",
            "  Epoch  7: Train=12.0178%, Val=7.4826%, LR=0.000050, Time=42.3s\n",
            "  Epoch  8: Train=11.3125%, Val=7.3786%, LR=0.000050, Time=43.0s\n",
            "  Epoch  9: Train=10.7508%, Val=6.6845%, LR=0.000050, Time=42.7s\n",
            "  Epoch 10: Train=10.1017%, Val=6.1993%, LR=0.000050, Time=42.7s\n",
            "  Epoch 11: Train=9.5742%, Val=6.2236%, LR=0.000050, Time=42.7s\n",
            "  Epoch 12: Train=9.2768%, Val=5.7852%, LR=0.000050, Time=33.5s\n",
            "  Epoch 13: Train=8.7463%, Val=5.4939%, LR=0.000050, Time=42.2s\n",
            "  Epoch 14: Train=8.3832%, Val=5.4885%, LR=0.000050, Time=42.8s\n",
            "  Epoch 15: Train=8.0842%, Val=5.3069%, LR=0.000050, Time=42.5s\n",
            "  Epoch 16: Train=7.9791%, Val=5.1160%, LR=0.000050, Time=43.0s\n",
            "  Epoch 18: Train=7.4454%, Val=4.9531%, LR=0.000050, Time=33.5s\n",
            "  Epoch 19: Train=7.3553%, Val=4.7665%, LR=0.000050, Time=43.2s\n",
            "  Epoch 20: Train=7.0772%, Val=4.7629%, LR=0.000050, Time=42.3s\n",
            "  Epoch 21: Train=7.1222%, Val=4.7559%, LR=0.000050, Time=43.3s\n",
            "  Epoch 22: Train=6.9052%, Val=4.6813%, LR=0.000050, Time=43.6s\n",
            "  Epoch 24: Train=6.6388%, Val=4.6451%, LR=0.000050, Time=33.5s\n",
            "  Epoch 25: Train=6.4737%, Val=4.3539%, LR=0.000050, Time=43.0s\n",
            "  Epoch 26: Train=6.3867%, Val=4.3646%, LR=0.000050, Time=43.4s\n",
            "  Epoch 28: Train=6.1501%, Val=4.3407%, LR=0.000050, Time=33.8s\n",
            "‚úÖ Fold 3 Seed 42 complete: Best Val MAPE = 4.3407% in 20.6min\n",
            "üöÄ Training Fold 3 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=94.8935%, Val=35.4057%, LR=0.000050, Time=34.2s\n",
            "  Epoch  2: Train=38.4768%, Val=16.7670%, LR=0.000050, Time=35.6s\n",
            "  Epoch  3: Train=24.6686%, Val=13.7960%, LR=0.000050, Time=43.3s\n",
            "  Epoch  4: Train=18.9225%, Val=12.0642%, LR=0.000050, Time=43.1s\n",
            "  Epoch  5: Train=15.9267%, Val=10.4250%, LR=0.000050, Time=43.5s\n",
            "  Epoch  6: Train=14.0610%, Val=9.2982%, LR=0.000050, Time=43.1s\n",
            "  Epoch  7: Train=12.6733%, Val=8.8877%, LR=0.000050, Time=42.9s\n",
            "  Epoch  8: Train=11.7149%, Val=7.8998%, LR=0.000050, Time=43.1s\n",
            "  Epoch  9: Train=10.9977%, Val=7.7419%, LR=0.000050, Time=43.3s\n",
            "  Epoch 11: Train=9.7929%, Val=7.2664%, LR=0.000050, Time=34.5s\n",
            "  Epoch 12: Train=9.1409%, Val=6.0705%, LR=0.000050, Time=43.4s\n",
            "  Epoch 16: Train=7.9568%, Val=6.0280%, LR=0.000050, Time=34.9s\n",
            "  Epoch 18: Train=7.6130%, Val=5.3419%, LR=0.000050, Time=34.2s\n",
            "  Epoch 20: Train=7.2913%, Val=5.0008%, LR=0.000050, Time=34.5s\n",
            "  Epoch 21: Train=7.0794%, Val=5.1583%, LR=0.000050, Time=42.8s\n",
            "  Epoch 26: Train=6.6697%, Val=4.9793%, LR=0.000050, Time=34.1s\n",
            "  Epoch 27: Train=6.3607%, Val=4.9094%, LR=0.000050, Time=43.3s\n",
            "  Epoch 28: Train=6.4392%, Val=4.8069%, LR=0.000050, Time=43.0s\n",
            "  Epoch 29: Train=6.3337%, Val=4.6381%, LR=0.000050, Time=43.1s\n",
            "‚úÖ Fold 3 Seed 123 complete: Best Val MAPE = 4.6381% in 20.0min\n",
            "üöÄ Training Fold 3 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=117.2136%, Val=33.5895%, LR=0.000050, Time=34.3s\n",
            "  Epoch  2: Train=41.8438%, Val=18.2647%, LR=0.000050, Time=35.9s\n",
            "  Epoch  3: Train=24.9892%, Val=14.6997%, LR=0.000050, Time=43.3s\n",
            "  Epoch  4: Train=18.9430%, Val=11.0477%, LR=0.000050, Time=43.4s\n",
            "  Epoch  5: Train=15.7333%, Val=8.9736%, LR=0.000050, Time=43.0s\n",
            "  Epoch  6: Train=13.8521%, Val=8.1352%, LR=0.000050, Time=42.7s\n",
            "  Epoch  7: Train=12.6131%, Val=7.3486%, LR=0.000050, Time=43.5s\n",
            "  Epoch  9: Train=11.0863%, Val=6.9460%, LR=0.000050, Time=34.1s\n",
            "  Epoch 10: Train=10.5022%, Val=6.7768%, LR=0.000050, Time=43.6s\n",
            "  Epoch 11: Train=10.1536%, Val=6.2028%, LR=0.000050, Time=42.8s\n",
            "  Epoch 13: Train=9.2067%, Val=5.6061%, LR=0.000050, Time=34.4s\n",
            "  Epoch 16: Train=8.0596%, Val=5.1634%, LR=0.000050, Time=34.5s\n",
            "  Epoch 18: Train=7.7078%, Val=4.8621%, LR=0.000050, Time=34.5s\n",
            "  Epoch 19: Train=7.4478%, Val=4.8303%, LR=0.000050, Time=43.0s\n",
            "  Epoch 21: Train=7.2163%, Val=4.5609%, LR=0.000050, Time=34.5s\n",
            "  Epoch 24: Train=6.8721%, Val=4.5066%, LR=0.000050, Time=34.0s\n",
            "  Epoch 25: Train=6.7960%, Val=4.4968%, LR=0.000050, Time=42.9s\n",
            "  Epoch 26: Train=6.7341%, Val=5.0653%, LR=0.000050, Time=42.6s\n",
            "  Epoch 27: Train=6.5670%, Val=4.4382%, LR=0.000050, Time=34.2s\n",
            "  Epoch 29: Train=6.4947%, Val=4.3033%, LR=0.000050, Time=34.2s\n",
            "‚úÖ Fold 3 Seed 456 complete: Best Val MAPE = 4.3033% in 20.1min\n",
            "üìà Fold 3 ensemble results:\n",
            "   Mean MAPE: 4.4274% ¬± 0.1498%\n",
            "   Best MAPE: 4.3033%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 60.9 minutes\n",
            "\n",
            "üéØ Training Fold 4 with 3 seeds\n",
            "üöÄ Training Fold 4 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=136.8803%, Val=38.5134%, LR=0.000050, Time=33.5s\n",
            "  Epoch  2: Train=41.3244%, Val=19.6310%, LR=0.000050, Time=35.9s\n",
            "  Epoch  3: Train=23.8000%, Val=13.5059%, LR=0.000050, Time=43.4s\n",
            "  Epoch  4: Train=18.2185%, Val=10.3529%, LR=0.000050, Time=42.9s\n",
            "  Epoch  5: Train=15.6559%, Val=9.6982%, LR=0.000050, Time=43.2s\n",
            "  Epoch  6: Train=13.5602%, Val=7.7864%, LR=0.000050, Time=42.8s\n",
            "  Epoch  8: Train=11.5158%, Val=7.0144%, LR=0.000050, Time=34.1s\n",
            "  Epoch 10: Train=10.2270%, Val=6.5035%, LR=0.000050, Time=34.4s\n",
            "  Epoch 11: Train=9.6780%, Val=6.0818%, LR=0.000050, Time=42.8s\n",
            "  Epoch 12: Train=9.3705%, Val=5.8428%, LR=0.000050, Time=43.3s\n",
            "  Epoch 13: Train=8.7631%, Val=5.6655%, LR=0.000050, Time=42.4s\n",
            "  Epoch 14: Train=8.5110%, Val=5.4376%, LR=0.000050, Time=42.9s\n",
            "  Epoch 15: Train=8.1230%, Val=5.2073%, LR=0.000050, Time=43.2s\n",
            "  Epoch 16: Train=7.9414%, Val=5.0237%, LR=0.000050, Time=43.3s\n",
            "  Epoch 19: Train=7.3790%, Val=4.8110%, LR=0.000050, Time=34.1s\n",
            "  Epoch 20: Train=7.2179%, Val=4.7046%, LR=0.000050, Time=43.1s\n",
            "  Epoch 21: Train=7.0929%, Val=4.8953%, LR=0.000050, Time=43.3s\n",
            "  Epoch 24: Train=6.7672%, Val=4.4924%, LR=0.000050, Time=34.2s\n",
            "  Epoch 25: Train=6.5771%, Val=4.3985%, LR=0.000050, Time=43.1s\n",
            "  Epoch 26: Train=6.5921%, Val=4.5317%, LR=0.000050, Time=43.2s\n",
            "  Epoch 29: Train=6.2851%, Val=4.1948%, LR=0.000050, Time=34.3s\n",
            "‚úÖ Fold 4 Seed 42 complete: Best Val MAPE = 4.1948% in 20.1min\n",
            "üöÄ Training Fold 4 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=94.9601%, Val=34.9315%, LR=0.000050, Time=34.1s\n",
            "  Epoch  2: Train=38.1271%, Val=17.0108%, LR=0.000050, Time=35.4s\n",
            "  Epoch  3: Train=24.1603%, Val=12.8384%, LR=0.000050, Time=42.7s\n",
            "  Epoch  4: Train=18.6667%, Val=11.8353%, LR=0.000050, Time=43.1s\n",
            "  Epoch  5: Train=15.4886%, Val=10.5338%, LR=0.000050, Time=43.4s\n",
            "  Epoch  6: Train=13.8447%, Val=9.2757%, LR=0.000050, Time=43.0s\n",
            "  Epoch  7: Train=12.5911%, Val=8.6864%, LR=0.000050, Time=42.6s\n",
            "  Epoch  8: Train=11.5965%, Val=7.9578%, LR=0.000050, Time=42.8s\n",
            "  Epoch  9: Train=10.9747%, Val=7.4134%, LR=0.000050, Time=43.1s\n",
            "  Epoch 11: Train=9.8117%, Val=6.9189%, LR=0.000050, Time=33.7s\n",
            "  Epoch 12: Train=9.2354%, Val=6.7444%, LR=0.000050, Time=42.7s\n",
            "  Epoch 13: Train=8.8360%, Val=5.9503%, LR=0.000050, Time=42.7s\n",
            "  Epoch 15: Train=8.1993%, Val=5.7781%, LR=0.000050, Time=33.6s\n",
            "  Epoch 16: Train=7.9811%, Val=5.3489%, LR=0.000050, Time=42.4s\n",
            "  Epoch 20: Train=7.2930%, Val=5.2631%, LR=0.000050, Time=34.1s\n",
            "  Epoch 21: Train=7.0987%, Val=5.2635%, LR=0.000050, Time=42.9s\n",
            "  Epoch 22: Train=6.9418%, Val=5.0290%, LR=0.000050, Time=34.0s\n",
            "  Epoch 23: Train=6.9377%, Val=4.7895%, LR=0.000050, Time=42.8s\n",
            "  Epoch 26: Train=6.7062%, Val=4.7998%, LR=0.000050, Time=34.6s\n",
            "  Epoch 28: Train=6.4686%, Val=4.6999%, LR=0.000050, Time=33.6s\n",
            "‚úÖ Fold 4 Seed 123 complete: Best Val MAPE = 4.6999% in 19.9min\n",
            "üöÄ Training Fold 4 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=117.2229%, Val=33.5208%, LR=0.000050, Time=33.8s\n",
            "  Epoch  2: Train=42.1642%, Val=19.5232%, LR=0.000050, Time=34.8s\n",
            "  Epoch  3: Train=25.2221%, Val=13.2649%, LR=0.000050, Time=42.5s\n",
            "  Epoch  4: Train=19.3000%, Val=10.8720%, LR=0.000050, Time=42.4s\n",
            "  Epoch  5: Train=16.0769%, Val=9.1960%, LR=0.000050, Time=42.8s\n",
            "  Epoch  6: Train=13.8782%, Val=8.4718%, LR=0.000050, Time=43.1s\n",
            "  Epoch  7: Train=12.8145%, Val=7.4127%, LR=0.000050, Time=42.9s\n",
            "  Epoch  8: Train=11.8271%, Val=7.2071%, LR=0.000050, Time=43.0s\n",
            "  Epoch  9: Train=11.1760%, Val=7.0404%, LR=0.000050, Time=42.5s\n",
            "  Epoch 10: Train=10.5985%, Val=6.2435%, LR=0.000050, Time=43.0s\n",
            "  Epoch 11: Train=10.1502%, Val=6.4039%, LR=0.000050, Time=42.7s\n",
            "  Epoch 14: Train=8.8051%, Val=5.8845%, LR=0.000050, Time=34.3s\n",
            "  Epoch 16: Train=8.1286%, Val=5.0752%, LR=0.000050, Time=33.7s\n",
            "  Epoch 18: Train=7.7288%, Val=4.9190%, LR=0.000050, Time=33.8s\n",
            "  Epoch 21: Train=7.2549%, Val=4.7122%, LR=0.000050, Time=34.3s\n",
            "  Epoch 22: Train=7.1846%, Val=4.6527%, LR=0.000050, Time=42.7s\n",
            "  Epoch 24: Train=6.7908%, Val=4.4313%, LR=0.000050, Time=33.7s\n",
            "  Epoch 26: Train=6.8427%, Val=4.8026%, LR=0.000050, Time=33.8s\n",
            "  Epoch 29: Train=6.3622%, Val=4.3246%, LR=0.000050, Time=33.8s\n",
            "‚úÖ Fold 4 Seed 456 complete: Best Val MAPE = 4.3246% in 19.6min\n",
            "üìà Fold 4 ensemble results:\n",
            "   Mean MAPE: 4.4064% ¬± 0.2142%\n",
            "   Best MAPE: 4.1948%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 59.7 minutes\n",
            "\n",
            "============================================================\n",
            "üìä COMPREHENSIVE ENSEMBLE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "üìã Individual Fold Analysis:\n",
            "Fold   Best     Mean     Std      Seeds       \n",
            "--------------------------------------------------\n",
            "0      4.2638   4.4438   0.2352   3           \n",
            "1      4.2209   4.3754   0.2127   3           \n",
            "2      4.2856   4.3452   0.0638   3           \n",
            "3      4.3033   4.4274   0.1498   3           \n",
            "4      4.1948   4.4064   0.2142   3           \n",
            "\n",
            "üéØ Overall Performance Summary:\n",
            "   Total models trained: 15\n",
            "   Overall mean MAPE: 4.3996% ¬± 0.1893%\n",
            "   Best single model: 4.1948%\n",
            "   Expected ensemble MAPE: 4.3996%\n",
            "   Total training time: 6.55 hours\n",
            "   Average time per model: 26.2 minutes\n",
            "\n",
            "üìà Performance Analysis:\n",
            "   Best single fold performance: 4.1948%\n",
            "   Mean of best fold performances: 4.2537%\n",
            "   Stability improvement: 0.1893% standard deviation\n",
            "\n",
            "üèÜ Competition Analysis:\n",
            "   Models below 3.0% target: 0/15\n",
            "   Success rate: 0.0%\n",
            "   üéØ Gap to target: 1.1948%\n",
            "üíæ Results saved to:\n",
            "   /content/drive/MyDrive/ThinkOnward/Result/Phase2c/ensemble_results.json\n",
            "   /content/drive/MyDrive/ThinkOnward/Result/Phase2c/training_summary.txt\n",
            "\n",
            "‚úÖ Phase 2c Training Complete!\n",
            "Ready for diffusion model development in Phase 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimized training for StabilizedUnet and tweaked parameters for performance improvement\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x0K2zUAZLrk",
        "outputId": "f375fb7d-dde2-48d4-a95d-4f348e169245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Phase 2c Optimized Training Pipeline\n",
            "   Target: Sub-3.0% MAPE with stable ensemble\n",
            "   Strategy: 5 folds √ó 3 seeds = 15 models\n",
            "   Hardware: A100 GPU with batch_size=32\n",
            "üéØ Multi-Seed Trainer initialized\n",
            "   Data: /content/drive/MyDrive/ThinkOnward/Data/Train\n",
            "   Results: /content/drive/MyDrive/ThinkOnward/Result/Phase2c\n",
            "   Seeds: [42, 123, 456]\n",
            "   Total models to train: 15\n",
            "\n",
            "============================================================\n",
            "üöÄ STARTING OPTIMIZED MULTI-SEED ENSEMBLE TRAINING\n",
            "============================================================\n",
            "üìä Created 5-fold splits\n",
            "\n",
            "üéØ Training Fold 0 with 3 seeds\n",
            "üöÄ Training Fold 0 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b01f5097713b>:19: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:217.)\n",
            "  attention = torch.bmm(query, key)\n",
            "<ipython-input-7-b01f5097713b>:22: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:217.)\n",
            "  out = torch.bmm(value, attention.permute(0, 2, 1))\n",
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:217.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch  1: Train=81.8903%, Val=26.2064%, LR=0.000010, Time=3347.3s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 9.53e-06\n",
            "  Epoch  2: Train=26.2609%, Val=13.4480%, LR=0.000093, Time=35.1s\n",
            "    üìâ Learning rate reduced: 9.53e-06 ‚Üí 9.29e-05\n",
            "  Epoch  3: Train=19.5851%, Val=10.2425%, LR=0.000100, Time=42.5s\n",
            "    üìâ Learning rate reduced: 9.29e-05 ‚Üí 1.00e-04\n",
            "  Epoch  4: Train=14.3343%, Val=8.7828%, LR=0.000005, Time=42.3s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 4.58e-06\n",
            "  Epoch  5: Train=11.9677%, Val=6.8735%, LR=0.000023, Time=42.2s\n",
            "    üìâ Learning rate reduced: 4.58e-06 ‚Üí 2.30e-05\n",
            "  Epoch  6: Train=11.5396%, Val=6.6761%, LR=0.000026, Time=42.5s\n",
            "    üìâ Learning rate reduced: 2.30e-05 ‚Üí 2.56e-05\n",
            "  Epoch  7: Train=11.1392%, Val=6.5268%, LR=0.000028, Time=42.5s\n",
            "    üìâ Learning rate reduced: 2.56e-05 ‚Üí 2.77e-05\n",
            "  Epoch  8: Train=10.5482%, Val=6.2672%, LR=0.000031, Time=42.4s\n",
            "    üìâ Learning rate reduced: 2.77e-05 ‚Üí 3.13e-05\n",
            "  Epoch  9: Train=10.1990%, Val=6.0243%, LR=0.000035, Time=42.2s\n",
            "    üìâ Learning rate reduced: 3.13e-05 ‚Üí 3.48e-05\n",
            "  Epoch 10: Train=9.5853%, Val=5.8271%, LR=0.000038, Time=41.9s\n",
            "    üìâ Learning rate reduced: 3.48e-05 ‚Üí 3.78e-05\n",
            "  Epoch 11: Train=9.3072%, Val=5.5037%, LR=0.000043, Time=42.5s\n",
            "    üìâ Learning rate reduced: 3.78e-05 ‚Üí 4.27e-05\n",
            "  Epoch 12: Train=8.9120%, Val=5.1176%, LR=0.000049, Time=42.2s\n",
            "    üìâ Learning rate reduced: 4.27e-05 ‚Üí 4.87e-05\n",
            "  Epoch 13: Train=8.3941%, Val=5.0112%, LR=0.000050, Time=42.3s\n",
            "    üìâ Learning rate reduced: 4.87e-05 ‚Üí 5.03e-05\n",
            "    üìâ Learning rate reduced: 5.03e-05 ‚Üí 4.20e-05\n",
            "    üìâ Learning rate reduced: 4.20e-05 ‚Üí 4.98e-05\n",
            "  Epoch 16: Train=7.5200%, Val=4.5542%, LR=0.000057, Time=33.8s\n",
            "    üìâ Learning rate reduced: 4.98e-05 ‚Üí 5.74e-05\n",
            "    üìâ Learning rate reduced: 5.74e-05 ‚Üí 4.78e-05\n",
            "    üìâ Learning rate reduced: 4.78e-05 ‚Üí 5.51e-05\n",
            "  Epoch 19: Train=6.8204%, Val=4.5463%, LR=0.000058, Time=33.4s\n",
            "    üìâ Learning rate reduced: 5.51e-05 ‚Üí 5.75e-05\n",
            "  Epoch 20: Train=6.6043%, Val=4.3575%, LR=0.000060, Time=42.7s\n",
            "    üìâ Learning rate reduced: 5.75e-05 ‚Üí 6.04e-05\n",
            "  Epoch 21: Train=6.6729%, Val=4.3012%, LR=0.000061, Time=42.5s\n",
            "    üìâ Learning rate reduced: 6.04e-05 ‚Üí 6.13e-05\n",
            "    üìâ Learning rate reduced: 6.13e-05 ‚Üí 5.80e-05\n",
            "    üìâ Learning rate reduced: 5.80e-05 ‚Üí 5.57e-05\n",
            "    üìâ Learning rate reduced: 5.57e-05 ‚Üí 6.06e-05\n",
            "  Epoch 25: Train=6.1593%, Val=4.2680%, LR=0.000062, Time=33.7s\n",
            "    üìâ Learning rate reduced: 6.06e-05 ‚Üí 6.18e-05\n",
            "  Epoch 26: Train=5.9345%, Val=4.6584%, LR=0.000056, Time=42.5s\n",
            "    üìâ Learning rate reduced: 6.18e-05 ‚Üí 5.58e-05\n",
            "  Epoch 27: Train=5.8765%, Val=4.1379%, LR=0.000064, Time=34.1s\n",
            "    üìâ Learning rate reduced: 5.58e-05 ‚Üí 6.37e-05\n",
            "    üìâ Learning rate reduced: 6.37e-05 ‚Üí 5.81e-05\n",
            "  Epoch 29: Train=5.6942%, Val=3.8925%, LR=0.000067, Time=34.0s\n",
            "    üìâ Learning rate reduced: 5.81e-05 ‚Üí 6.74e-05\n",
            "    üìâ Learning rate reduced: 6.74e-05 ‚Üí 6.03e-05\n",
            "  Epoch 31: Train=5.5579%, Val=4.3929%, LR=0.000060, Time=33.7s\n",
            "    üìâ Learning rate reduced: 6.03e-05 ‚Üí 5.99e-05\n",
            "    üìâ Learning rate reduced: 5.99e-05 ‚Üí 5.81e-05\n",
            "    üìâ Learning rate reduced: 5.81e-05 ‚Üí 6.72e-05\n",
            "    üìâ Learning rate reduced: 6.72e-05 ‚Üí 6.22e-05\n",
            "    üìâ Learning rate reduced: 6.22e-05 ‚Üí 6.22e-05\n",
            "‚úÖ Fold 0 Seed 42 complete: Best Val MAPE = 3.8925% in 78.1min\n",
            "üöÄ Training Fold 0 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=59.9879%, Val=25.1693%, LR=0.000015, Time=34.0s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 1.46e-05\n",
            "  Epoch  2: Train=24.7879%, Val=13.3640%, LR=0.000093, Time=34.8s\n",
            "    üìâ Learning rate reduced: 1.46e-05 ‚Üí 9.32e-05\n",
            "  Epoch  3: Train=18.8954%, Val=10.1589%, LR=0.000100, Time=42.8s\n",
            "    üìâ Learning rate reduced: 9.32e-05 ‚Üí 1.00e-04\n",
            "  Epoch  4: Train=14.0549%, Val=9.2909%, LR=0.000002, Time=42.6s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 2.22e-06\n",
            "  Epoch  5: Train=12.0648%, Val=7.4735%, LR=0.000016, Time=43.0s\n",
            "    üìâ Learning rate reduced: 2.22e-06 ‚Üí 1.58e-05\n",
            "  Epoch  6: Train=11.6646%, Val=7.4948%, LR=0.000016, Time=42.1s\n",
            "    üìâ Learning rate reduced: 1.58e-05 ‚Üí 1.56e-05\n",
            "  Epoch  7: Train=11.2420%, Val=6.9237%, LR=0.000022, Time=33.8s\n",
            "    üìâ Learning rate reduced: 1.56e-05 ‚Üí 2.24e-05\n",
            "  Epoch  8: Train=10.8373%, Val=6.7975%, LR=0.000024, Time=42.5s\n",
            "    üìâ Learning rate reduced: 2.24e-05 ‚Üí 2.40e-05\n",
            "  Epoch  9: Train=10.5089%, Val=6.7665%, LR=0.000024, Time=42.5s\n",
            "    üìâ Learning rate reduced: 2.40e-05 ‚Üí 2.44e-05\n",
            "  Epoch 10: Train=10.1203%, Val=6.3766%, LR=0.000030, Time=43.0s\n",
            "    üìâ Learning rate reduced: 2.44e-05 ‚Üí 2.98e-05\n",
            "  Epoch 11: Train=9.6548%, Val=6.2014%, LR=0.000032, Time=42.8s\n",
            "    üìâ Learning rate reduced: 2.98e-05 ‚Üí 3.23e-05\n",
            "  Epoch 12: Train=9.0984%, Val=5.8223%, LR=0.000038, Time=43.3s\n",
            "    üìâ Learning rate reduced: 3.23e-05 ‚Üí 3.79e-05\n",
            "  Epoch 13: Train=8.7340%, Val=5.3983%, LR=0.000044, Time=42.3s\n",
            "    üìâ Learning rate reduced: 3.79e-05 ‚Üí 4.43e-05\n",
            "    üìâ Learning rate reduced: 4.43e-05 ‚Üí 4.05e-05\n",
            "    üìâ Learning rate reduced: 4.05e-05 ‚Üí 3.08e-05\n",
            "  Epoch 16: Train=7.9138%, Val=5.2126%, LR=0.000047, Time=34.4s\n",
            "    üìâ Learning rate reduced: 3.08e-05 ‚Üí 4.72e-05\n",
            "    üìâ Learning rate reduced: 4.72e-05 ‚Üí 4.70e-05\n",
            "  Epoch 18: Train=7.4149%, Val=4.9971%, LR=0.000051, Time=34.8s\n",
            "    üìâ Learning rate reduced: 4.70e-05 ‚Üí 5.05e-05\n",
            "    üìâ Learning rate reduced: 5.05e-05 ‚Üí 3.72e-05\n",
            "  Epoch 20: Train=6.9058%, Val=4.7372%, LR=0.000055, Time=33.8s\n",
            "    üìâ Learning rate reduced: 3.72e-05 ‚Üí 5.46e-05\n",
            "  Epoch 21: Train=6.8060%, Val=4.9476%, LR=0.000051, Time=42.8s\n",
            "    üìâ Learning rate reduced: 5.46e-05 ‚Üí 5.13e-05\n",
            "    üìâ Learning rate reduced: 5.13e-05 ‚Üí 5.22e-05\n",
            "    üìâ Learning rate reduced: 5.22e-05 ‚Üí 5.44e-05\n",
            "    üìâ Learning rate reduced: 5.44e-05 ‚Üí 4.02e-05\n",
            "  Epoch 25: Train=6.2798%, Val=4.6152%, LR=0.000056, Time=33.8s\n",
            "    üìâ Learning rate reduced: 4.02e-05 ‚Üí 5.65e-05\n",
            "  Epoch 26: Train=6.3414%, Val=4.4124%, LR=0.000060, Time=42.8s\n",
            "    üìâ Learning rate reduced: 5.65e-05 ‚Üí 5.96e-05\n",
            "    üìâ Learning rate reduced: 5.96e-05 ‚Üí 5.67e-05\n",
            "    üìâ Learning rate reduced: 5.67e-05 ‚Üí 5.11e-05\n",
            "    üìâ Learning rate reduced: 5.11e-05 ‚Üí 5.66e-05\n",
            "  Epoch 30: Train=5.9484%, Val=4.2901%, LR=0.000061, Time=34.0s\n",
            "    üìâ Learning rate reduced: 5.66e-05 ‚Üí 6.14e-05\n",
            "  Epoch 31: Train=5.9398%, Val=4.1057%, LR=0.000064, Time=42.6s\n",
            "    üìâ Learning rate reduced: 6.14e-05 ‚Üí 6.42e-05\n",
            "    üìâ Learning rate reduced: 6.42e-05 ‚Üí 6.35e-05\n",
            "    üìâ Learning rate reduced: 6.35e-05 ‚Üí 5.65e-05\n",
            "    üìâ Learning rate reduced: 5.65e-05 ‚Üí 5.54e-05\n",
            "    üìâ Learning rate reduced: 5.54e-05 ‚Üí 6.42e-05\n",
            "‚úÖ Fold 0 Seed 123 complete: Best Val MAPE = 4.1057% in 22.7min\n",
            "üöÄ Training Fold 0 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=72.6345%, Val=26.9079%, LR=0.000007, Time=33.6s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 6.72e-06\n",
            "  Epoch  2: Train=27.2868%, Val=15.4638%, LR=0.000083, Time=34.0s\n",
            "    üìâ Learning rate reduced: 6.72e-06 ‚Üí 8.29e-05\n",
            "  Epoch  3: Train=20.4402%, Val=10.6448%, LR=0.000100, Time=42.7s\n",
            "    üìâ Learning rate reduced: 8.29e-05 ‚Üí 9.97e-05\n",
            "  Epoch  4: Train=14.6999%, Val=9.1385%, LR=0.000003, Time=42.9s\n",
            "    üìâ Learning rate reduced: 9.97e-05 ‚Üí 2.80e-06\n",
            "  Epoch  5: Train=12.5426%, Val=7.1002%, LR=0.000020, Time=42.7s\n",
            "    üìâ Learning rate reduced: 2.80e-06 ‚Üí 2.02e-05\n",
            "  Epoch  6: Train=12.0510%, Val=6.8096%, LR=0.000024, Time=42.8s\n",
            "    üìâ Learning rate reduced: 2.02e-05 ‚Üí 2.39e-05\n",
            "  Epoch  7: Train=11.5335%, Val=6.6646%, LR=0.000026, Time=42.7s\n",
            "    üìâ Learning rate reduced: 2.39e-05 ‚Üí 2.58e-05\n",
            "    üìâ Learning rate reduced: 2.58e-05 ‚Üí 2.36e-05\n",
            "  Epoch  9: Train=10.5548%, Val=6.1592%, LR=0.000033, Time=33.8s\n",
            "    üìâ Learning rate reduced: 2.36e-05 ‚Üí 3.29e-05\n",
            "    üìâ Learning rate reduced: 3.29e-05 ‚Üí 3.20e-05\n",
            "  Epoch 11: Train=9.6339%, Val=6.0307%, LR=0.000035, Time=33.7s\n",
            "    üìâ Learning rate reduced: 3.20e-05 ‚Üí 3.47e-05\n",
            "  Epoch 12: Train=9.2406%, Val=5.6034%, LR=0.000041, Time=42.8s\n",
            "    üìâ Learning rate reduced: 3.47e-05 ‚Üí 4.12e-05\n",
            "    üìâ Learning rate reduced: 4.12e-05 ‚Üí 3.72e-05\n",
            "  Epoch 14: Train=8.4515%, Val=5.2632%, LR=0.000046, Time=34.5s\n",
            "    üìâ Learning rate reduced: 3.72e-05 ‚Üí 4.64e-05\n",
            "  Epoch 15: Train=8.1812%, Val=5.1137%, LR=0.000049, Time=42.8s\n",
            "    üìâ Learning rate reduced: 4.64e-05 ‚Üí 4.87e-05\n",
            "  Epoch 16: Train=7.9153%, Val=5.0242%, LR=0.000050, Time=43.4s\n",
            "    üìâ Learning rate reduced: 4.87e-05 ‚Üí 5.01e-05\n",
            "  Epoch 17: Train=7.5572%, Val=4.9462%, LR=0.000051, Time=43.0s\n",
            "    üìâ Learning rate reduced: 5.01e-05 ‚Üí 5.13e-05\n",
            "  Epoch 18: Train=7.3102%, Val=4.6869%, LR=0.000055, Time=42.6s\n",
            "    üìâ Learning rate reduced: 5.13e-05 ‚Üí 5.54e-05\n",
            "    üìâ Learning rate reduced: 5.54e-05 ‚Üí 5.17e-05\n",
            "    üìâ Learning rate reduced: 5.17e-05 ‚Üí 4.94e-05\n",
            "  Epoch 21: Train=6.6907%, Val=4.4315%, LR=0.000059, Time=33.9s\n",
            "    üìâ Learning rate reduced: 4.94e-05 ‚Üí 5.93e-05\n",
            "    üìâ Learning rate reduced: 5.93e-05 ‚Üí 5.83e-05\n",
            "    üìâ Learning rate reduced: 5.83e-05 ‚Üí 5.80e-05\n",
            "  Epoch 24: Train=6.3616%, Val=4.1186%, LR=0.000064, Time=33.9s\n",
            "    üìâ Learning rate reduced: 5.80e-05 ‚Üí 6.40e-05\n",
            "    üìâ Learning rate reduced: 6.40e-05 ‚Üí 5.77e-05\n",
            "  Epoch 26: Train=6.1080%, Val=4.3225%, LR=0.000061, Time=34.2s\n",
            "    üìâ Learning rate reduced: 5.77e-05 ‚Üí 6.10e-05\n",
            "    üìâ Learning rate reduced: 6.10e-05 ‚Üí 6.34e-05\n",
            "    üìâ Learning rate reduced: 6.34e-05 ‚Üí 6.15e-05\n",
            "    üìâ Learning rate reduced: 6.15e-05 ‚Üí 5.86e-05\n",
            "    üìâ Learning rate reduced: 5.86e-05 ‚Üí 6.07e-05\n",
            "  Epoch 31: Train=5.8074%, Val=3.9362%, LR=0.000067, Time=33.9s\n",
            "    üìâ Learning rate reduced: 6.07e-05 ‚Üí 6.67e-05\n",
            "    üìâ Learning rate reduced: 6.67e-05 ‚Üí 6.23e-05\n",
            "    üìâ Learning rate reduced: 6.23e-05 ‚Üí 5.80e-05\n",
            "  Epoch 34: Train=5.4777%, Val=3.9147%, LR=0.000067, Time=33.9s\n",
            "    üìâ Learning rate reduced: 5.80e-05 ‚Üí 6.71e-05\n",
            "    üìâ Learning rate reduced: 6.71e-05 ‚Üí 6.64e-05\n",
            "‚úÖ Fold 0 Seed 456 complete: Best Val MAPE = 3.9147% in 22.8min\n",
            "üìà Fold 0 ensemble results:\n",
            "   Mean MAPE: 3.9710% ¬± 0.0957%\n",
            "   Best MAPE: 3.8925%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 123.7 minutes\n",
            "\n",
            "üéØ Training Fold 1 with 3 seeds\n",
            "üöÄ Training Fold 1 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=81.4729%, Val=27.9409%, LR=0.000004, Time=34.1s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 3.57e-06\n",
            "  Epoch  2: Train=26.3048%, Val=14.2203%, LR=0.000090, Time=35.3s\n",
            "    üìâ Learning rate reduced: 3.57e-06 ‚Üí 8.95e-05\n",
            "  Epoch  3: Train=19.5845%, Val=9.9839%, LR=0.000001, Time=42.4s\n",
            "    üìâ Learning rate reduced: 8.95e-05 ‚Üí 1.00e-06\n",
            "  Epoch  4: Train=15.7497%, Val=8.3223%, LR=0.000008, Time=43.1s\n",
            "    üìâ Learning rate reduced: 1.00e-06 ‚Üí 7.72e-06\n",
            "  Epoch  5: Train=15.1124%, Val=8.1891%, LR=0.000009, Time=42.8s\n",
            "    üìâ Learning rate reduced: 7.72e-06 ‚Üí 8.80e-06\n",
            "  Epoch  6: Train=14.3870%, Val=7.5189%, LR=0.000015, Time=42.7s\n",
            "    üìâ Learning rate reduced: 8.80e-06 ‚Üí 1.53e-05\n",
            "  Epoch  7: Train=13.7675%, Val=7.1516%, LR=0.000020, Time=42.5s\n",
            "    üìâ Learning rate reduced: 1.53e-05 ‚Üí 1.95e-05\n",
            "  Epoch  8: Train=12.9437%, Val=6.8100%, LR=0.000024, Time=42.3s\n",
            "    üìâ Learning rate reduced: 1.95e-05 ‚Üí 2.38e-05\n",
            "  Epoch  9: Train=12.1447%, Val=6.7671%, LR=0.000024, Time=42.5s\n",
            "    üìâ Learning rate reduced: 2.38e-05 ‚Üí 2.44e-05\n",
            "  Epoch 10: Train=11.4398%, Val=6.3843%, LR=0.000030, Time=42.2s\n",
            "    üìâ Learning rate reduced: 2.44e-05 ‚Üí 2.96e-05\n",
            "  Epoch 11: Train=10.9000%, Val=6.0597%, LR=0.000034, Time=42.6s\n",
            "    üìâ Learning rate reduced: 2.96e-05 ‚Üí 3.43e-05\n",
            "  Epoch 12: Train=10.3892%, Val=5.9029%, LR=0.000037, Time=42.0s\n",
            "    üìâ Learning rate reduced: 3.43e-05 ‚Üí 3.66e-05\n",
            "  Epoch 13: Train=9.7829%, Val=5.7232%, LR=0.000039, Time=42.4s\n",
            "    üìâ Learning rate reduced: 3.66e-05 ‚Üí 3.94e-05\n",
            "    üìâ Learning rate reduced: 3.94e-05 ‚Üí 3.77e-05\n",
            "  Epoch 15: Train=8.9638%, Val=5.1717%, LR=0.000048, Time=34.1s\n",
            "    üìâ Learning rate reduced: 3.77e-05 ‚Üí 4.78e-05\n",
            "  Epoch 16: Train=8.6893%, Val=4.9765%, LR=0.000051, Time=42.7s\n",
            "    üìâ Learning rate reduced: 4.78e-05 ‚Üí 5.09e-05\n",
            "  Epoch 17: Train=8.3268%, Val=4.7909%, LR=0.000054, Time=42.7s\n",
            "    üìâ Learning rate reduced: 5.09e-05 ‚Üí 5.37e-05\n",
            "    üìâ Learning rate reduced: 5.37e-05 ‚Üí 5.25e-05\n",
            "  Epoch 19: Train=7.4738%, Val=4.7220%, LR=0.000055, Time=34.6s\n",
            "    üìâ Learning rate reduced: 5.25e-05 ‚Üí 5.48e-05\n",
            "  Epoch 20: Train=7.2886%, Val=4.5272%, LR=0.000058, Time=42.5s\n",
            "    üìâ Learning rate reduced: 5.48e-05 ‚Üí 5.78e-05\n",
            "  Epoch 21: Train=7.0983%, Val=4.5399%, LR=0.000058, Time=42.7s\n",
            "    üìâ Learning rate reduced: 5.78e-05 ‚Üí 5.76e-05\n",
            "  Epoch 22: Train=6.9936%, Val=4.2688%, LR=0.000062, Time=34.3s\n",
            "    üìâ Learning rate reduced: 5.76e-05 ‚Üí 6.18e-05\n",
            "    üìâ Learning rate reduced: 6.18e-05 ‚Üí 6.03e-05\n",
            "    üìâ Learning rate reduced: 6.03e-05 ‚Üí 4.97e-05\n",
            "    üìâ Learning rate reduced: 4.97e-05 ‚Üí 6.04e-05\n",
            "  Epoch 26: Train=6.3623%, Val=4.1178%, LR=0.000064, Time=34.2s\n",
            "    üìâ Learning rate reduced: 6.04e-05 ‚Üí 6.40e-05\n",
            "    üìâ Learning rate reduced: 6.40e-05 ‚Üí 5.87e-05\n",
            "    üìâ Learning rate reduced: 5.87e-05 ‚Üí 5.96e-05\n",
            "  Epoch 29: Train=6.0087%, Val=3.9927%, LR=0.000066, Time=34.9s\n",
            "    üìâ Learning rate reduced: 5.96e-05 ‚Üí 6.59e-05\n",
            "    üìâ Learning rate reduced: 6.59e-05 ‚Üí 6.08e-05\n",
            "  Epoch 31: Train=5.8393%, Val=4.1117%, LR=0.000064, Time=34.1s\n",
            "    üìâ Learning rate reduced: 6.08e-05 ‚Üí 6.41e-05\n",
            "    üìâ Learning rate reduced: 6.41e-05 ‚Üí 6.19e-05\n",
            "    üìâ Learning rate reduced: 6.19e-05 ‚Üí 6.43e-05\n",
            "    üìâ Learning rate reduced: 6.43e-05 ‚Üí 5.52e-05\n",
            "    üìâ Learning rate reduced: 5.52e-05 ‚Üí 6.52e-05\n",
            "‚úÖ Fold 1 Seed 42 complete: Best Val MAPE = 3.9927% in 23.1min\n",
            "üöÄ Training Fold 1 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=60.2761%, Val=25.5191%, LR=0.000013, Time=34.5s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 1.28e-05\n",
            "  Epoch  2: Train=24.9779%, Val=13.4441%, LR=0.000093, Time=35.2s\n",
            "    üìâ Learning rate reduced: 1.28e-05 ‚Üí 9.29e-05\n",
            "  Epoch  3: Train=19.1517%, Val=10.6558%, LR=0.000100, Time=42.3s\n",
            "    üìâ Learning rate reduced: 9.29e-05 ‚Üí 9.97e-05\n",
            "  Epoch  4: Train=14.2626%, Val=8.6843%, LR=0.000005, Time=42.2s\n",
            "    üìâ Learning rate reduced: 9.97e-05 ‚Üí 5.17e-06\n",
            "  Epoch  5: Train=12.2826%, Val=7.0183%, LR=0.000021, Time=42.9s\n",
            "    üìâ Learning rate reduced: 5.17e-06 ‚Üí 2.12e-05\n",
            "  Epoch  6: Train=11.8609%, Val=7.1054%, LR=0.000020, Time=42.8s\n",
            "    üìâ Learning rate reduced: 2.12e-05 ‚Üí 2.01e-05\n",
            "  Epoch  7: Train=11.2645%, Val=6.6450%, LR=0.000026, Time=33.9s\n",
            "    üìâ Learning rate reduced: 2.01e-05 ‚Üí 2.60e-05\n",
            "  Epoch  8: Train=10.7294%, Val=6.6132%, LR=0.000026, Time=42.8s\n",
            "    üìâ Learning rate reduced: 2.60e-05 ‚Üí 2.65e-05\n",
            "  Epoch  9: Train=10.4232%, Val=6.4616%, LR=0.000029, Time=42.5s\n",
            "    üìâ Learning rate reduced: 2.65e-05 ‚Üí 2.86e-05\n",
            "  Epoch 10: Train=9.9865%, Val=5.9804%, LR=0.000035, Time=42.4s\n",
            "    üìâ Learning rate reduced: 2.86e-05 ‚Üí 3.55e-05\n",
            "  Epoch 11: Train=9.3749%, Val=5.6959%, LR=0.000040, Time=43.0s\n",
            "    üìâ Learning rate reduced: 3.55e-05 ‚Üí 3.98e-05\n",
            "    üìâ Learning rate reduced: 3.98e-05 ‚Üí 3.93e-05\n",
            "  Epoch 13: Train=8.6000%, Val=5.2880%, LR=0.000046, Time=33.8s\n",
            "    üìâ Learning rate reduced: 3.93e-05 ‚Üí 4.60e-05\n",
            "  Epoch 14: Train=8.3053%, Val=5.2430%, LR=0.000047, Time=42.4s\n",
            "    üìâ Learning rate reduced: 4.60e-05 ‚Üí 4.67e-05\n",
            "  Epoch 15: Train=7.8689%, Val=5.0343%, LR=0.000050, Time=42.3s\n",
            "    üìâ Learning rate reduced: 4.67e-05 ‚Üí 5.00e-05\n",
            "  Epoch 16: Train=7.8753%, Val=5.3315%, LR=0.000045, Time=42.8s\n",
            "    üìâ Learning rate reduced: 5.00e-05 ‚Üí 4.54e-05\n",
            "  Epoch 17: Train=7.3877%, Val=4.8552%, LR=0.000053, Time=33.6s\n",
            "    üìâ Learning rate reduced: 4.54e-05 ‚Üí 5.28e-05\n",
            "    üìâ Learning rate reduced: 5.28e-05 ‚Üí 4.67e-05\n",
            "    üìâ Learning rate reduced: 4.67e-05 ‚Üí 4.03e-05\n",
            "  Epoch 20: Train=6.8232%, Val=4.4106%, LR=0.000060, Time=33.8s\n",
            "    üìâ Learning rate reduced: 4.03e-05 ‚Üí 5.96e-05\n",
            "  Epoch 21: Train=6.7748%, Val=4.7215%, LR=0.000055, Time=42.5s\n",
            "    üìâ Learning rate reduced: 5.96e-05 ‚Üí 5.48e-05\n",
            "    üìâ Learning rate reduced: 5.48e-05 ‚Üí 5.38e-05\n",
            "    üìâ Learning rate reduced: 5.38e-05 ‚Üí 5.48e-05\n",
            "    üìâ Learning rate reduced: 5.48e-05 ‚Üí 4.92e-05\n",
            "    üìâ Learning rate reduced: 4.92e-05 ‚Üí 5.54e-05\n",
            "  Epoch 26: Train=6.2082%, Val=4.0789%, LR=0.000065, Time=33.4s\n",
            "    üìâ Learning rate reduced: 5.54e-05 ‚Üí 6.46e-05\n",
            "    üìâ Learning rate reduced: 6.46e-05 ‚Üí 5.52e-05\n",
            "    üìâ Learning rate reduced: 5.52e-05 ‚Üí 6.07e-05\n",
            "    üìâ Learning rate reduced: 6.07e-05 ‚Üí 6.17e-05\n",
            "    üìâ Learning rate reduced: 6.17e-05 ‚Üí 5.98e-05\n",
            "  Epoch 31: Train=5.9838%, Val=4.7111%, LR=0.000055, Time=33.5s\n",
            "    üìâ Learning rate reduced: 5.98e-05 ‚Üí 5.50e-05\n",
            "  Epoch 32: Train=5.7768%, Val=3.9801%, LR=0.000066, Time=33.7s\n",
            "    üìâ Learning rate reduced: 5.50e-05 ‚Üí 6.61e-05\n",
            "    üìâ Learning rate reduced: 6.61e-05 ‚Üí 5.72e-05\n",
            "    üìâ Learning rate reduced: 5.72e-05 ‚Üí 4.69e-05\n",
            "    üìâ Learning rate reduced: 4.69e-05 ‚Üí 6.53e-05\n",
            "‚úÖ Fold 1 Seed 123 complete: Best Val MAPE = 3.9801% in 22.4min\n",
            "üöÄ Training Fold 1 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=72.8387%, Val=26.2399%, LR=0.000009, Time=33.7s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 9.39e-06\n",
            "  Epoch  2: Train=26.8877%, Val=14.7616%, LR=0.000087, Time=35.0s\n",
            "    üìâ Learning rate reduced: 9.39e-06 ‚Üí 8.68e-05\n",
            "  Epoch  3: Train=20.0188%, Val=9.8817%, LR=0.000001, Time=42.7s\n",
            "    üìâ Learning rate reduced: 8.68e-05 ‚Üí 1.03e-06\n",
            "  Epoch  4: Train=15.9932%, Val=8.5573%, LR=0.000006, Time=42.1s\n",
            "    üìâ Learning rate reduced: 1.03e-06 ‚Üí 6.00e-06\n",
            "  Epoch  5: Train=15.5212%, Val=8.1275%, LR=0.000009, Time=42.6s\n",
            "    üìâ Learning rate reduced: 6.00e-06 ‚Üí 9.32e-06\n",
            "  Epoch  6: Train=14.9354%, Val=7.8149%, LR=0.000012, Time=42.4s\n",
            "    üìâ Learning rate reduced: 9.32e-06 ‚Üí 1.22e-05\n",
            "  Epoch  7: Train=14.1622%, Val=7.5149%, LR=0.000015, Time=42.7s\n",
            "    üìâ Learning rate reduced: 1.22e-05 ‚Üí 1.53e-05\n",
            "  Epoch  8: Train=13.5215%, Val=7.1885%, LR=0.000019, Time=42.7s\n",
            "    üìâ Learning rate reduced: 1.53e-05 ‚Üí 1.91e-05\n",
            "  Epoch  9: Train=12.9145%, Val=6.8407%, LR=0.000023, Time=42.9s\n",
            "    üìâ Learning rate reduced: 1.91e-05 ‚Üí 2.34e-05\n",
            "  Epoch 10: Train=12.2336%, Val=6.5020%, LR=0.000028, Time=42.7s\n",
            "    üìâ Learning rate reduced: 2.34e-05 ‚Üí 2.80e-05\n",
            "  Epoch 11: Train=11.6995%, Val=6.2489%, LR=0.000032, Time=42.6s\n",
            "    üìâ Learning rate reduced: 2.80e-05 ‚Üí 3.16e-05\n",
            "    üìâ Learning rate reduced: 3.16e-05 ‚Üí 2.96e-05\n",
            "  Epoch 13: Train=10.5355%, Val=6.2467%, LR=0.000032, Time=34.4s\n",
            "    üìâ Learning rate reduced: 2.96e-05 ‚Üí 3.16e-05\n",
            "  Epoch 14: Train=9.9696%, Val=5.6657%, LR=0.000040, Time=42.6s\n",
            "    üìâ Learning rate reduced: 3.16e-05 ‚Üí 4.02e-05\n",
            "  Epoch 15: Train=9.6336%, Val=5.5927%, LR=0.000041, Time=42.8s\n",
            "    üìâ Learning rate reduced: 4.02e-05 ‚Üí 4.13e-05\n",
            "  Epoch 16: Train=9.1053%, Val=5.8713%, LR=0.000037, Time=42.8s\n",
            "    üìâ Learning rate reduced: 4.13e-05 ‚Üí 3.71e-05\n",
            "  Epoch 17: Train=8.7062%, Val=5.4372%, LR=0.000044, Time=34.1s\n",
            "    üìâ Learning rate reduced: 3.71e-05 ‚Üí 4.37e-05\n",
            "  Epoch 18: Train=8.4299%, Val=5.2617%, LR=0.000046, Time=42.9s\n",
            "    üìâ Learning rate reduced: 4.37e-05 ‚Üí 4.64e-05\n",
            "  Epoch 19: Train=8.0739%, Val=4.8468%, LR=0.000053, Time=42.5s\n",
            "    üìâ Learning rate reduced: 4.64e-05 ‚Üí 5.29e-05\n",
            "    üìâ Learning rate reduced: 5.29e-05 ‚Üí 4.78e-05\n",
            "  Epoch 21: Train=7.5129%, Val=4.9692%, LR=0.000051, Time=34.1s\n",
            "    üìâ Learning rate reduced: 4.78e-05 ‚Üí 5.10e-05\n",
            "  Epoch 22: Train=7.3027%, Val=4.6446%, LR=0.000056, Time=33.3s\n",
            "    üìâ Learning rate reduced: 5.10e-05 ‚Üí 5.60e-05\n",
            "    üìâ Learning rate reduced: 5.60e-05 ‚Üí 5.54e-05\n",
            "  Epoch 24: Train=6.9034%, Val=4.3835%, LR=0.000060, Time=33.6s\n",
            "    üìâ Learning rate reduced: 5.54e-05 ‚Üí 6.00e-05\n",
            "    üìâ Learning rate reduced: 6.00e-05 ‚Üí 4.96e-05\n",
            "  Epoch 26: Train=6.6505%, Val=4.3554%, LR=0.000060, Time=33.8s\n",
            "    üìâ Learning rate reduced: 4.96e-05 ‚Üí 6.05e-05\n",
            "  Epoch 27: Train=6.5018%, Val=4.1596%, LR=0.000063, Time=42.7s\n",
            "    üìâ Learning rate reduced: 6.05e-05 ‚Üí 6.34e-05\n",
            "    üìâ Learning rate reduced: 6.34e-05 ‚Üí 5.87e-05\n",
            "    üìâ Learning rate reduced: 5.87e-05 ‚Üí 6.19e-05\n",
            "  Epoch 30: Train=6.0373%, Val=4.1168%, LR=0.000064, Time=33.9s\n",
            "    üìâ Learning rate reduced: 6.19e-05 ‚Üí 6.41e-05\n",
            "  Epoch 31: Train=6.0640%, Val=3.9774%, LR=0.000066, Time=42.5s\n",
            "    üìâ Learning rate reduced: 6.41e-05 ‚Üí 6.61e-05\n",
            "    üìâ Learning rate reduced: 6.61e-05 ‚Üí 5.80e-05\n",
            "    üìâ Learning rate reduced: 5.80e-05 ‚Üí 6.11e-05\n",
            "    üìâ Learning rate reduced: 6.11e-05 ‚Üí 6.40e-05\n",
            "  Epoch 35: Train=5.6866%, Val=3.8839%, LR=0.000068, Time=33.5s\n",
            "    üìâ Learning rate reduced: 6.40e-05 ‚Üí 6.75e-05\n",
            "‚úÖ Fold 1 Seed 456 complete: Best Val MAPE = 3.8839% in 23.4min\n",
            "üìà Fold 1 ensemble results:\n",
            "   Mean MAPE: 3.9522% ¬± 0.0486%\n",
            "   Best MAPE: 3.8839%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 68.9 minutes\n",
            "\n",
            "üéØ Training Fold 2 with 3 seeds\n",
            "üöÄ Training Fold 2 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=81.0541%, Val=27.9986%, LR=0.000003, Time=41.0s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 3.43e-06\n",
            "  Epoch  2: Train=25.9912%, Val=14.7964%, LR=0.000087, Time=35.1s\n",
            "    üìâ Learning rate reduced: 3.43e-06 ‚Üí 8.66e-05\n",
            "  Epoch  3: Train=19.3368%, Val=12.2691%, LR=0.000097, Time=42.0s\n",
            "    üìâ Learning rate reduced: 8.66e-05 ‚Üí 9.69e-05\n",
            "  Epoch  4: Train=14.1256%, Val=9.4359%, LR=0.000002, Time=42.2s\n",
            "    üìâ Learning rate reduced: 9.69e-05 ‚Üí 1.78e-06\n",
            "  Epoch  5: Train=12.0177%, Val=7.0645%, LR=0.000021, Time=42.3s\n",
            "    üìâ Learning rate reduced: 1.78e-06 ‚Üí 2.06e-05\n",
            "  Epoch  6: Train=11.4661%, Val=6.7299%, LR=0.000025, Time=42.3s\n",
            "    üìâ Learning rate reduced: 2.06e-05 ‚Üí 2.49e-05\n",
            "  Epoch  7: Train=11.1156%, Val=6.7048%, LR=0.000025, Time=42.3s\n",
            "    üìâ Learning rate reduced: 2.49e-05 ‚Üí 2.52e-05\n",
            "  Epoch  8: Train=10.4906%, Val=6.3379%, LR=0.000030, Time=42.3s\n",
            "    üìâ Learning rate reduced: 2.52e-05 ‚Üí 3.03e-05\n",
            "  Epoch  9: Train=10.1312%, Val=6.2443%, LR=0.000032, Time=42.6s\n",
            "    üìâ Learning rate reduced: 3.03e-05 ‚Üí 3.16e-05\n",
            "  Epoch 10: Train=9.6861%, Val=6.1227%, LR=0.000033, Time=42.2s\n",
            "    üìâ Learning rate reduced: 3.16e-05 ‚Üí 3.34e-05\n",
            "  Epoch 11: Train=9.4163%, Val=5.8247%, LR=0.000038, Time=41.8s\n",
            "    üìâ Learning rate reduced: 3.34e-05 ‚Üí 3.78e-05\n",
            "  Epoch 12: Train=8.9967%, Val=5.5477%, LR=0.000042, Time=42.2s\n",
            "    üìâ Learning rate reduced: 3.78e-05 ‚Üí 4.20e-05\n",
            "  Epoch 13: Train=8.5600%, Val=5.1893%, LR=0.000048, Time=42.3s\n",
            "    üìâ Learning rate reduced: 4.20e-05 ‚Üí 4.76e-05\n",
            "    üìâ Learning rate reduced: 4.76e-05 ‚Üí 4.71e-05\n",
            "  Epoch 15: Train=7.8909%, Val=4.8569%, LR=0.000053, Time=33.3s\n",
            "    üìâ Learning rate reduced: 4.71e-05 ‚Üí 5.27e-05\n",
            "  Epoch 16: Train=7.5815%, Val=4.7379%, LR=0.000055, Time=42.7s\n",
            "    üìâ Learning rate reduced: 5.27e-05 ‚Üí 5.46e-05\n",
            "    üìâ Learning rate reduced: 5.46e-05 ‚Üí 5.32e-05\n",
            "    üìâ Learning rate reduced: 5.32e-05 ‚Üí 4.79e-05\n",
            "  Epoch 19: Train=6.8495%, Val=4.6250%, LR=0.000056, Time=33.4s\n",
            "    üìâ Learning rate reduced: 4.79e-05 ‚Üí 5.63e-05\n",
            "  Epoch 20: Train=6.7436%, Val=4.3963%, LR=0.000060, Time=42.4s\n",
            "    üìâ Learning rate reduced: 5.63e-05 ‚Üí 5.98e-05\n",
            "  Epoch 21: Train=6.6388%, Val=4.7146%, LR=0.000055, Time=42.8s\n",
            "    üìâ Learning rate reduced: 5.98e-05 ‚Üí 5.49e-05\n",
            "  Epoch 22: Train=6.3612%, Val=4.3538%, LR=0.000060, Time=33.7s\n",
            "    üìâ Learning rate reduced: 5.49e-05 ‚Üí 6.05e-05\n",
            "    üìâ Learning rate reduced: 6.05e-05 ‚Üí 5.75e-05\n",
            "    üìâ Learning rate reduced: 5.75e-05 ‚Üí 5.92e-05\n",
            "  Epoch 25: Train=6.1302%, Val=4.2404%, LR=0.000062, Time=33.7s\n",
            "    üìâ Learning rate reduced: 5.92e-05 ‚Üí 6.22e-05\n",
            "  Epoch 26: Train=5.9765%, Val=4.0487%, LR=0.000065, Time=42.6s\n",
            "    üìâ Learning rate reduced: 6.22e-05 ‚Üí 6.51e-05\n",
            "    üìâ Learning rate reduced: 6.51e-05 ‚Üí 6.07e-05\n",
            "    üìâ Learning rate reduced: 6.07e-05 ‚Üí 6.19e-05\n",
            "    üìâ Learning rate reduced: 6.19e-05 ‚Üí 6.29e-05\n",
            "    üìâ Learning rate reduced: 6.29e-05 ‚Üí 5.21e-05\n",
            "  Epoch 31: Train=5.6325%, Val=4.2251%, LR=0.000062, Time=33.7s\n",
            "    üìâ Learning rate reduced: 5.21e-05 ‚Üí 6.24e-05\n",
            "    üìâ Learning rate reduced: 6.24e-05 ‚Üí 6.15e-05\n",
            "    üìâ Learning rate reduced: 6.15e-05 ‚Üí 6.47e-05\n",
            "    üìâ Learning rate reduced: 6.47e-05 ‚Üí 5.10e-05\n",
            "    ‚èπÔ∏è  Early stopping at epoch 34\n",
            "‚úÖ Fold 2 Seed 42 complete: Best Val MAPE = 4.0487% in 22.3min\n",
            "üöÄ Training Fold 2 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=60.2857%, Val=25.8099%, LR=0.000011, Time=34.0s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 1.13e-05\n",
            "  Epoch  2: Train=25.4712%, Val=13.8527%, LR=0.000091, Time=35.3s\n",
            "    üìâ Learning rate reduced: 1.13e-05 ‚Üí 9.12e-05\n",
            "  Epoch  3: Train=19.3518%, Val=10.9938%, LR=0.000099, Time=42.9s\n",
            "    üìâ Learning rate reduced: 9.12e-05 ‚Üí 9.94e-05\n",
            "  Epoch  4: Train=14.7884%, Val=9.1261%, LR=0.000003, Time=42.8s\n",
            "    üìâ Learning rate reduced: 9.94e-05 ‚Üí 2.85e-06\n",
            "  Epoch  5: Train=12.6565%, Val=7.5679%, LR=0.000015, Time=42.7s\n",
            "    üìâ Learning rate reduced: 2.85e-06 ‚Üí 1.48e-05\n",
            "  Epoch  6: Train=12.1248%, Val=7.2004%, LR=0.000019, Time=42.7s\n",
            "    üìâ Learning rate reduced: 1.48e-05 ‚Üí 1.89e-05\n",
            "  Epoch  7: Train=11.7149%, Val=7.1455%, LR=0.000020, Time=43.4s\n",
            "    üìâ Learning rate reduced: 1.89e-05 ‚Üí 1.96e-05\n",
            "  Epoch  8: Train=11.0925%, Val=6.8341%, LR=0.000024, Time=42.4s\n",
            "    üìâ Learning rate reduced: 1.96e-05 ‚Üí 2.35e-05\n",
            "  Epoch  9: Train=10.8052%, Val=6.7460%, LR=0.000025, Time=42.5s\n",
            "    üìâ Learning rate reduced: 2.35e-05 ‚Üí 2.47e-05\n",
            "  Epoch 10: Train=10.4294%, Val=6.7122%, LR=0.000025, Time=42.7s\n",
            "    üìâ Learning rate reduced: 2.47e-05 ‚Üí 2.51e-05\n",
            "  Epoch 11: Train=9.8430%, Val=6.5472%, LR=0.000027, Time=42.8s\n",
            "    üìâ Learning rate reduced: 2.51e-05 ‚Üí 2.74e-05\n",
            "  Epoch 12: Train=9.5568%, Val=6.1295%, LR=0.000033, Time=42.9s\n",
            "    üìâ Learning rate reduced: 2.74e-05 ‚Üí 3.33e-05\n",
            "    üìâ Learning rate reduced: 3.33e-05 ‚Üí 3.01e-05\n",
            "  Epoch 14: Train=8.6877%, Val=5.9163%, LR=0.000036, Time=33.8s\n",
            "    üìâ Learning rate reduced: 3.01e-05 ‚Üí 3.64e-05\n",
            "  Epoch 15: Train=8.4472%, Val=5.8343%, LR=0.000038, Time=42.8s\n",
            "    üìâ Learning rate reduced: 3.64e-05 ‚Üí 3.77e-05\n",
            "  Epoch 16: Train=8.1472%, Val=5.3673%, LR=0.000045, Time=42.3s\n",
            "    üìâ Learning rate reduced: 3.77e-05 ‚Üí 4.48e-05\n",
            "  Epoch 17: Train=7.7627%, Val=5.2097%, LR=0.000047, Time=42.4s\n",
            "    üìâ Learning rate reduced: 4.48e-05 ‚Üí 4.72e-05\n",
            "    üìâ Learning rate reduced: 4.72e-05 ‚Üí 4.47e-05\n",
            "    üìâ Learning rate reduced: 4.47e-05 ‚Üí 3.81e-05\n",
            "  Epoch 20: Train=7.0918%, Val=4.8600%, LR=0.000053, Time=34.2s\n",
            "    üìâ Learning rate reduced: 3.81e-05 ‚Üí 5.27e-05\n",
            "  Epoch 21: Train=7.0370%, Val=4.7462%, LR=0.000054, Time=42.9s\n",
            "    üìâ Learning rate reduced: 5.27e-05 ‚Üí 5.44e-05\n",
            "    üìâ Learning rate reduced: 5.44e-05 ‚Üí 5.29e-05\n",
            "  Epoch 23: Train=6.5637%, Val=4.6403%, LR=0.000056, Time=34.0s\n",
            "    üìâ Learning rate reduced: 5.29e-05 ‚Üí 5.61e-05\n",
            "    üìâ Learning rate reduced: 5.61e-05 ‚Üí 4.78e-05\n",
            "    üìâ Learning rate reduced: 4.78e-05 ‚Üí 5.36e-05\n",
            "  Epoch 26: Train=6.3824%, Val=4.7069%, LR=0.000055, Time=33.5s\n",
            "    üìâ Learning rate reduced: 5.36e-05 ‚Üí 5.51e-05\n",
            "  Epoch 27: Train=6.2211%, Val=4.5474%, LR=0.000058, Time=34.0s\n",
            "    üìâ Learning rate reduced: 5.51e-05 ‚Üí 5.75e-05\n",
            "  Epoch 28: Train=6.4280%, Val=4.2985%, LR=0.000061, Time=43.1s\n",
            "    üìâ Learning rate reduced: 5.75e-05 ‚Üí 6.13e-05\n",
            "    üìâ Learning rate reduced: 6.13e-05 ‚Üí 5.67e-05\n",
            "  Epoch 30: Train=6.1526%, Val=4.2263%, LR=0.000062, Time=34.3s\n",
            "    üìâ Learning rate reduced: 5.67e-05 ‚Üí 6.24e-05\n",
            "  Epoch 31: Train=6.0272%, Val=4.4528%, LR=0.000059, Time=42.9s\n",
            "    üìâ Learning rate reduced: 6.24e-05 ‚Üí 5.90e-05\n",
            "    üìâ Learning rate reduced: 5.90e-05 ‚Üí 6.12e-05\n",
            "    üìâ Learning rate reduced: 6.12e-05 ‚Üí 6.10e-05\n",
            "    üìâ Learning rate reduced: 6.10e-05 ‚Üí 5.54e-05\n",
            "  Epoch 35: Train=5.6584%, Val=4.0185%, LR=0.000066, Time=34.0s\n",
            "    üìâ Learning rate reduced: 5.54e-05 ‚Üí 6.55e-05\n",
            "‚úÖ Fold 2 Seed 123 complete: Best Val MAPE = 4.0185% in 23.3min\n",
            "üöÄ Training Fold 2 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=72.6726%, Val=25.8382%, LR=0.000011, Time=42.4s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 1.12e-05\n",
            "  Epoch  2: Train=26.7048%, Val=14.7863%, LR=0.000087, Time=34.4s\n",
            "    üìâ Learning rate reduced: 1.12e-05 ‚Üí 8.67e-05\n",
            "  Epoch  3: Train=19.9502%, Val=11.5745%, LR=0.000098, Time=42.0s\n",
            "    üìâ Learning rate reduced: 8.67e-05 ‚Üí 9.85e-05\n",
            "  Epoch  4: Train=14.2158%, Val=8.0444%, LR=0.000010, Time=42.7s\n",
            "    üìâ Learning rate reduced: 9.85e-05 ‚Üí 1.01e-05\n",
            "  Epoch  5: Train=11.9822%, Val=6.8514%, LR=0.000023, Time=42.2s\n",
            "    üìâ Learning rate reduced: 1.01e-05 ‚Üí 2.33e-05\n",
            "  Epoch  6: Train=11.4895%, Val=6.7788%, LR=0.000024, Time=43.0s\n",
            "    üìâ Learning rate reduced: 2.33e-05 ‚Üí 2.43e-05\n",
            "  Epoch  7: Train=10.9277%, Val=6.4528%, LR=0.000029, Time=42.0s\n",
            "    üìâ Learning rate reduced: 2.43e-05 ‚Üí 2.87e-05\n",
            "    üìâ Learning rate reduced: 2.87e-05 ‚Üí 2.71e-05\n",
            "  Epoch  9: Train=9.9883%, Val=6.1460%, LR=0.000033, Time=33.4s\n",
            "    üìâ Learning rate reduced: 2.71e-05 ‚Üí 3.31e-05\n",
            "  Epoch 10: Train=9.6537%, Val=5.8150%, LR=0.000038, Time=42.1s\n",
            "    üìâ Learning rate reduced: 3.31e-05 ‚Üí 3.80e-05\n",
            "  Epoch 11: Train=9.0748%, Val=5.6065%, LR=0.000041, Time=42.1s\n",
            "    üìâ Learning rate reduced: 3.80e-05 ‚Üí 4.11e-05\n",
            "    üìâ Learning rate reduced: 4.11e-05 ‚Üí 3.74e-05\n",
            "  Epoch 13: Train=8.4456%, Val=5.3305%, LR=0.000045, Time=33.2s\n",
            "    üìâ Learning rate reduced: 3.74e-05 ‚Üí 4.54e-05\n",
            "    üìâ Learning rate reduced: 4.54e-05 ‚Üí 4.39e-05\n",
            "  Epoch 15: Train=7.8454%, Val=5.2154%, LR=0.000047, Time=33.5s\n",
            "    üìâ Learning rate reduced: 4.39e-05 ‚Üí 4.72e-05\n",
            "  Epoch 16: Train=7.6112%, Val=4.8602%, LR=0.000053, Time=42.7s\n",
            "    üìâ Learning rate reduced: 4.72e-05 ‚Üí 5.27e-05\n",
            "  Epoch 17: Train=7.3407%, Val=4.6690%, LR=0.000056, Time=42.2s\n",
            "    üìâ Learning rate reduced: 5.27e-05 ‚Üí 5.56e-05\n",
            "    üìâ Learning rate reduced: 5.56e-05 ‚Üí 5.00e-05\n",
            "    üìâ Learning rate reduced: 5.00e-05 ‚Üí 5.33e-05\n",
            "  Epoch 20: Train=6.8883%, Val=4.4745%, LR=0.000059, Time=33.4s\n",
            "    üìâ Learning rate reduced: 5.33e-05 ‚Üí 5.86e-05\n",
            "  Epoch 21: Train=6.7132%, Val=4.5317%, LR=0.000058, Time=42.6s\n",
            "    üìâ Learning rate reduced: 5.86e-05 ‚Üí 5.78e-05\n",
            "  Epoch 22: Train=6.5263%, Val=4.4050%, LR=0.000060, Time=33.8s\n",
            "    üìâ Learning rate reduced: 5.78e-05 ‚Üí 5.97e-05\n",
            "  Epoch 23: Train=6.3062%, Val=4.3630%, LR=0.000060, Time=42.2s\n",
            "    üìâ Learning rate reduced: 5.97e-05 ‚Üí 6.03e-05\n",
            "  Epoch 24: Train=6.4335%, Val=4.2179%, LR=0.000063, Time=42.5s\n",
            "    üìâ Learning rate reduced: 6.03e-05 ‚Üí 6.25e-05\n",
            "    üìâ Learning rate reduced: 6.25e-05 ‚Üí 5.90e-05\n",
            "  Epoch 26: Train=6.0477%, Val=4.2002%, LR=0.000063, Time=33.8s\n",
            "    üìâ Learning rate reduced: 5.90e-05 ‚Üí 6.28e-05\n",
            "  Epoch 27: Train=6.1145%, Val=3.9780%, LR=0.000066, Time=42.4s\n",
            "    üìâ Learning rate reduced: 6.28e-05 ‚Üí 6.61e-05\n",
            "    üìâ Learning rate reduced: 6.61e-05 ‚Üí 5.62e-05\n",
            "    üìâ Learning rate reduced: 5.62e-05 ‚Üí 6.11e-05\n",
            "    üìâ Learning rate reduced: 6.11e-05 ‚Üí 6.22e-05\n",
            "  Epoch 31: Train=5.7015%, Val=3.9774%, LR=0.000066, Time=33.5s\n",
            "    üìâ Learning rate reduced: 6.22e-05 ‚Üí 6.61e-05\n",
            "    üìâ Learning rate reduced: 6.61e-05 ‚Üí 6.42e-05\n",
            "    üìâ Learning rate reduced: 6.42e-05 ‚Üí 6.13e-05\n",
            "  Epoch 34: Train=5.5383%, Val=3.9581%, LR=0.000066, Time=34.0s\n",
            "    üìâ Learning rate reduced: 6.13e-05 ‚Üí 6.64e-05\n",
            "    üìâ Learning rate reduced: 6.64e-05 ‚Üí 6.59e-05\n",
            "‚úÖ Fold 2 Seed 456 complete: Best Val MAPE = 3.9581% in 23.2min\n",
            "üìà Fold 2 ensemble results:\n",
            "   Mean MAPE: 4.0084% ¬± 0.0377%\n",
            "   Best MAPE: 3.9581%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 68.9 minutes\n",
            "\n",
            "üéØ Training Fold 3 with 3 seeds\n",
            "üöÄ Training Fold 3 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=81.5880%, Val=26.7393%, LR=0.000007, Time=33.9s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 7.35e-06\n",
            "  Epoch  2: Train=26.2124%, Val=14.6405%, LR=0.000087, Time=33.3s\n",
            "    üìâ Learning rate reduced: 7.35e-06 ‚Üí 8.74e-05\n",
            "  Epoch  3: Train=19.4166%, Val=13.2734%, LR=0.000094, Time=42.2s\n",
            "    üìâ Learning rate reduced: 8.74e-05 ‚Üí 9.36e-05\n",
            "  Epoch  4: Train=14.0734%, Val=7.6640%, LR=0.000014, Time=42.6s\n",
            "    üìâ Learning rate reduced: 9.36e-05 ‚Üí 1.37e-05\n",
            "  Epoch  5: Train=12.0248%, Val=7.1550%, LR=0.000019, Time=42.4s\n",
            "    üìâ Learning rate reduced: 1.37e-05 ‚Üí 1.95e-05\n",
            "  Epoch  6: Train=11.4022%, Val=6.6474%, LR=0.000026, Time=42.9s\n",
            "    üìâ Learning rate reduced: 1.95e-05 ‚Üí 2.60e-05\n",
            "  Epoch  7: Train=10.9515%, Val=6.4771%, LR=0.000028, Time=42.9s\n",
            "    üìâ Learning rate reduced: 2.60e-05 ‚Üí 2.83e-05\n",
            "  Epoch  8: Train=10.4258%, Val=6.3702%, LR=0.000030, Time=42.8s\n",
            "    üìâ Learning rate reduced: 2.83e-05 ‚Üí 2.98e-05\n",
            "  Epoch  9: Train=10.0615%, Val=6.1159%, LR=0.000033, Time=42.6s\n",
            "    üìâ Learning rate reduced: 2.98e-05 ‚Üí 3.35e-05\n",
            "  Epoch 10: Train=9.4461%, Val=5.8348%, LR=0.000038, Time=42.6s\n",
            "    üìâ Learning rate reduced: 3.35e-05 ‚Üí 3.77e-05\n",
            "  Epoch 11: Train=9.2199%, Val=6.0009%, LR=0.000035, Time=42.2s\n",
            "    üìâ Learning rate reduced: 3.77e-05 ‚Üí 3.52e-05\n",
            "  Epoch 12: Train=8.7591%, Val=5.4832%, LR=0.000043, Time=34.0s\n",
            "    üìâ Learning rate reduced: 3.52e-05 ‚Üí 4.30e-05\n",
            "  Epoch 13: Train=8.3477%, Val=5.1789%, LR=0.000048, Time=42.1s\n",
            "    üìâ Learning rate reduced: 4.30e-05 ‚Üí 4.77e-05\n",
            "    üìâ Learning rate reduced: 4.77e-05 ‚Üí 4.56e-05\n",
            "  Epoch 15: Train=7.8461%, Val=4.9428%, LR=0.000051, Time=33.4s\n",
            "    üìâ Learning rate reduced: 4.56e-05 ‚Üí 5.14e-05\n",
            "  Epoch 16: Train=7.5722%, Val=4.8261%, LR=0.000053, Time=42.3s\n",
            "    üìâ Learning rate reduced: 5.14e-05 ‚Üí 5.32e-05\n",
            "    üìâ Learning rate reduced: 5.32e-05 ‚Üí 4.92e-05\n",
            "    üìâ Learning rate reduced: 4.92e-05 ‚Üí 4.99e-05\n",
            "  Epoch 19: Train=7.0190%, Val=4.4441%, LR=0.000059, Time=33.6s\n",
            "    üìâ Learning rate reduced: 4.99e-05 ‚Üí 5.91e-05\n",
            "    üìâ Learning rate reduced: 5.91e-05 ‚Üí 5.58e-05\n",
            "  Epoch 21: Train=6.6287%, Val=4.5129%, LR=0.000058, Time=33.9s\n",
            "    üìâ Learning rate reduced: 5.58e-05 ‚Üí 5.80e-05\n",
            "    üìâ Learning rate reduced: 5.80e-05 ‚Üí 5.83e-05\n",
            "  Epoch 23: Train=6.4564%, Val=4.3623%, LR=0.000060, Time=34.3s\n",
            "    üìâ Learning rate reduced: 5.83e-05 ‚Üí 6.04e-05\n",
            "    üìâ Learning rate reduced: 6.04e-05 ‚Üí 5.78e-05\n",
            "  Epoch 25: Train=6.1068%, Val=4.2872%, LR=0.000061, Time=33.6s\n",
            "    üìâ Learning rate reduced: 5.78e-05 ‚Üí 6.15e-05\n",
            "  Epoch 26: Train=5.9998%, Val=4.1068%, LR=0.000064, Time=42.4s\n",
            "    üìâ Learning rate reduced: 6.15e-05 ‚Üí 6.42e-05\n",
            "  Epoch 27: Train=5.9848%, Val=4.0880%, LR=0.000064, Time=42.0s\n",
            "    üìâ Learning rate reduced: 6.42e-05 ‚Üí 6.45e-05\n",
            "    üìâ Learning rate reduced: 6.45e-05 ‚Üí 6.37e-05\n",
            "    üìâ Learning rate reduced: 6.37e-05 ‚Üí 6.32e-05\n",
            "    üìâ Learning rate reduced: 6.32e-05 ‚Üí 6.32e-05\n",
            "  Epoch 31: Train=5.5448%, Val=4.1735%, LR=0.000063, Time=33.8s\n",
            "    üìâ Learning rate reduced: 6.32e-05 ‚Üí 6.32e-05\n",
            "    üìâ Learning rate reduced: 6.32e-05 ‚Üí 6.35e-05\n",
            "  Epoch 33: Train=5.4017%, Val=3.9304%, LR=0.000067, Time=33.2s\n",
            "    üìâ Learning rate reduced: 6.35e-05 ‚Üí 6.68e-05\n",
            "    üìâ Learning rate reduced: 6.68e-05 ‚Üí 5.88e-05\n",
            "  Epoch 35: Train=5.3745%, Val=3.8525%, LR=0.000068, Time=33.7s\n",
            "    üìâ Learning rate reduced: 5.88e-05 ‚Üí 6.80e-05\n",
            "‚úÖ Fold 3 Seed 42 complete: Best Val MAPE = 3.8525% in 22.7min\n",
            "üöÄ Training Fold 3 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=60.3588%, Val=26.7895%, LR=0.000007, Time=42.1s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 7.16e-06\n",
            "  Epoch  2: Train=25.6058%, Val=14.4594%, LR=0.000088, Time=35.0s\n",
            "    üìâ Learning rate reduced: 7.16e-06 ‚Üí 8.83e-05\n",
            "  Epoch  3: Train=19.4535%, Val=11.7630%, LR=0.000098, Time=42.5s\n",
            "    üìâ Learning rate reduced: 8.83e-05 ‚Üí 9.81e-05\n",
            "  Epoch  4: Train=14.3033%, Val=10.0300%, LR=0.000100, Time=42.9s\n",
            "    üìâ Learning rate reduced: 9.81e-05 ‚Üí 1.00e-04\n",
            "  Epoch  5: Train=11.8836%, Val=7.7715%, LR=0.000013, Time=42.7s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 1.26e-05\n",
            "  Epoch  6: Train=10.4272%, Val=6.6812%, LR=0.000026, Time=42.7s\n",
            "    üìâ Learning rate reduced: 1.26e-05 ‚Üí 2.56e-05\n",
            "    üìâ Learning rate reduced: 2.56e-05 ‚Üí 2.39e-05\n",
            "  Epoch  8: Train=9.6900%, Val=6.3922%, LR=0.000030, Time=34.1s\n",
            "    üìâ Learning rate reduced: 2.39e-05 ‚Üí 2.95e-05\n",
            "  Epoch  9: Train=9.3976%, Val=5.9040%, LR=0.000037, Time=42.7s\n",
            "    üìâ Learning rate reduced: 2.95e-05 ‚Üí 3.66e-05\n",
            "    üìâ Learning rate reduced: 3.66e-05 ‚Üí 2.94e-05\n",
            "  Epoch 11: Train=8.4578%, Val=5.4039%, LR=0.000044, Time=33.4s\n",
            "    üìâ Learning rate reduced: 2.94e-05 ‚Üí 4.42e-05\n",
            "    üìâ Learning rate reduced: 4.42e-05 ‚Üí 3.23e-05\n",
            "  Epoch 13: Train=7.9005%, Val=5.2073%, LR=0.000047, Time=33.6s\n",
            "    üìâ Learning rate reduced: 3.23e-05 ‚Üí 4.73e-05\n",
            "    üìâ Learning rate reduced: 4.73e-05 ‚Üí 3.75e-05\n",
            "  Epoch 15: Train=7.4232%, Val=5.1761%, LR=0.000048, Time=33.6s\n",
            "    üìâ Learning rate reduced: 3.75e-05 ‚Üí 4.78e-05\n",
            "  Epoch 16: Train=7.2933%, Val=5.9033%, LR=0.000037, Time=42.4s\n",
            "    üìâ Learning rate reduced: 4.78e-05 ‚Üí 3.66e-05\n",
            "    üìâ Learning rate reduced: 3.66e-05 ‚Üí 4.63e-05\n",
            "  Epoch 18: Train=6.9625%, Val=4.9220%, LR=0.000052, Time=33.5s\n",
            "    üìâ Learning rate reduced: 4.63e-05 ‚Üí 5.17e-05\n",
            "    üìâ Learning rate reduced: 5.17e-05 ‚Üí 5.03e-05\n",
            "  Epoch 20: Train=6.5725%, Val=4.4426%, LR=0.000059, Time=34.3s\n",
            "    üìâ Learning rate reduced: 5.03e-05 ‚Üí 5.91e-05\n",
            "  Epoch 21: Train=6.5553%, Val=4.8251%, LR=0.000053, Time=42.8s\n",
            "    üìâ Learning rate reduced: 5.91e-05 ‚Üí 5.32e-05\n",
            "    üìâ Learning rate reduced: 5.32e-05 ‚Üí 5.17e-05\n",
            "    üìâ Learning rate reduced: 5.17e-05 ‚Üí 5.64e-05\n",
            "  Epoch 24: Train=6.3426%, Val=4.3709%, LR=0.000060, Time=33.1s\n",
            "    üìâ Learning rate reduced: 5.64e-05 ‚Üí 6.02e-05\n",
            "    üìâ Learning rate reduced: 6.02e-05 ‚Üí 4.86e-05\n",
            "  Epoch 26: Train=6.1057%, Val=4.1808%, LR=0.000063, Time=33.9s\n",
            "    üìâ Learning rate reduced: 4.86e-05 ‚Üí 6.31e-05\n",
            "    üìâ Learning rate reduced: 6.31e-05 ‚Üí 5.87e-05\n",
            "    üìâ Learning rate reduced: 5.87e-05 ‚Üí 4.99e-05\n",
            "    üìâ Learning rate reduced: 4.99e-05 ‚Üí 5.47e-05\n",
            "    üìâ Learning rate reduced: 5.47e-05 ‚Üí 5.08e-05\n",
            "  Epoch 31: Train=5.7200%, Val=4.2735%, LR=0.000062, Time=33.4s\n",
            "    üìâ Learning rate reduced: 5.08e-05 ‚Üí 6.17e-05\n",
            "    üìâ Learning rate reduced: 6.17e-05 ‚Üí 6.07e-05\n",
            "    üìâ Learning rate reduced: 6.07e-05 ‚Üí 5.41e-05\n",
            "    üìâ Learning rate reduced: 5.41e-05 ‚Üí 5.55e-05\n",
            "    ‚èπÔ∏è  Early stopping at epoch 34\n",
            "‚úÖ Fold 3 Seed 123 complete: Best Val MAPE = 4.1808% in 21.5min\n",
            "üöÄ Training Fold 3 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=72.7602%, Val=27.7041%, LR=0.000004, Time=33.0s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 4.18e-06\n",
            "  Epoch  2: Train=27.3822%, Val=16.2072%, LR=0.000078, Time=34.5s\n",
            "    üìâ Learning rate reduced: 4.18e-06 ‚Üí 7.83e-05\n",
            "  Epoch  3: Train=20.9730%, Val=12.3205%, LR=0.000097, Time=42.4s\n",
            "    üìâ Learning rate reduced: 7.83e-05 ‚Üí 9.67e-05\n",
            "  Epoch  4: Train=14.9415%, Val=10.3527%, LR=0.000100, Time=42.1s\n",
            "    üìâ Learning rate reduced: 9.67e-05 ‚Üí 9.99e-05\n",
            "  Epoch  5: Train=11.9265%, Val=8.2920%, LR=0.000008, Time=42.2s\n",
            "    üìâ Learning rate reduced: 9.99e-05 ‚Üí 7.96e-06\n",
            "  Epoch  6: Train=10.7587%, Val=6.7052%, LR=0.000025, Time=42.8s\n",
            "    üìâ Learning rate reduced: 7.96e-06 ‚Üí 2.52e-05\n",
            "  Epoch  7: Train=10.4145%, Val=6.4062%, LR=0.000029, Time=42.9s\n",
            "    üìâ Learning rate reduced: 2.52e-05 ‚Üí 2.93e-05\n",
            "    üìâ Learning rate reduced: 2.93e-05 ‚Üí 2.59e-05\n",
            "  Epoch  9: Train=9.6468%, Val=6.1232%, LR=0.000033, Time=33.5s\n",
            "    üìâ Learning rate reduced: 2.59e-05 ‚Üí 3.34e-05\n",
            "  Epoch 10: Train=9.3276%, Val=5.7577%, LR=0.000039, Time=42.4s\n",
            "    üìâ Learning rate reduced: 3.34e-05 ‚Üí 3.88e-05\n",
            "  Epoch 11: Train=9.0936%, Val=5.5998%, LR=0.000041, Time=42.5s\n",
            "    üìâ Learning rate reduced: 3.88e-05 ‚Üí 4.12e-05\n",
            "    üìâ Learning rate reduced: 4.12e-05 ‚Üí 4.09e-05\n",
            "  Epoch 13: Train=8.2556%, Val=5.3775%, LR=0.000045, Time=33.5s\n",
            "    üìâ Learning rate reduced: 4.09e-05 ‚Üí 4.46e-05\n",
            "  Epoch 14: Train=7.8879%, Val=4.9711%, LR=0.000051, Time=42.7s\n",
            "    üìâ Learning rate reduced: 4.46e-05 ‚Üí 5.09e-05\n",
            "    üìâ Learning rate reduced: 5.09e-05 ‚Üí 5.02e-05\n",
            "  Epoch 16: Train=7.3359%, Val=4.8659%, LR=0.000053, Time=33.4s\n",
            "    üìâ Learning rate reduced: 5.02e-05 ‚Üí 5.26e-05\n",
            "  Epoch 17: Train=7.2511%, Val=4.8518%, LR=0.000053, Time=42.6s\n",
            "    üìâ Learning rate reduced: 5.26e-05 ‚Üí 5.28e-05\n",
            "  Epoch 18: Train=6.9957%, Val=4.5699%, LR=0.000057, Time=42.2s\n",
            "    üìâ Learning rate reduced: 5.28e-05 ‚Üí 5.72e-05\n",
            "  Epoch 19: Train=6.8405%, Val=4.3633%, LR=0.000060, Time=42.5s\n",
            "    üìâ Learning rate reduced: 5.72e-05 ‚Üí 6.03e-05\n",
            "    üìâ Learning rate reduced: 6.03e-05 ‚Üí 5.16e-05\n",
            "  Epoch 21: Train=6.5232%, Val=4.4424%, LR=0.000059, Time=33.6s\n",
            "    üìâ Learning rate reduced: 5.16e-05 ‚Üí 5.91e-05\n",
            "  Epoch 22: Train=6.3228%, Val=4.2852%, LR=0.000062, Time=33.6s\n",
            "    üìâ Learning rate reduced: 5.91e-05 ‚Üí 6.15e-05\n",
            "    üìâ Learning rate reduced: 6.15e-05 ‚Üí 5.32e-05\n",
            "  Epoch 24: Train=6.4377%, Val=4.1493%, LR=0.000064, Time=33.7s\n",
            "    üìâ Learning rate reduced: 5.32e-05 ‚Üí 6.36e-05\n",
            "    üìâ Learning rate reduced: 6.36e-05 ‚Üí 5.96e-05\n",
            "  Epoch 26: Train=5.9704%, Val=4.0887%, LR=0.000064, Time=33.6s\n",
            "    üìâ Learning rate reduced: 5.96e-05 ‚Üí 6.45e-05\n",
            "  Epoch 27: Train=5.9849%, Val=4.0561%, LR=0.000065, Time=42.4s\n",
            "    üìâ Learning rate reduced: 6.45e-05 ‚Üí 6.50e-05\n",
            "    üìâ Learning rate reduced: 6.50e-05 ‚Üí 5.89e-05\n",
            "    üìâ Learning rate reduced: 5.89e-05 ‚Üí 6.31e-05\n",
            "    üìâ Learning rate reduced: 6.31e-05 ‚Üí 6.09e-05\n",
            "  Epoch 31: Train=5.7382%, Val=4.1817%, LR=0.000063, Time=33.4s\n",
            "    üìâ Learning rate reduced: 6.09e-05 ‚Üí 6.31e-05\n",
            "    üìâ Learning rate reduced: 6.31e-05 ‚Üí 6.18e-05\n",
            "    üìâ Learning rate reduced: 6.18e-05 ‚Üí 6.34e-05\n",
            "    üìâ Learning rate reduced: 6.34e-05 ‚Üí 6.12e-05\n",
            "  Epoch 35: Train=5.4526%, Val=3.8113%, LR=0.000069, Time=33.2s\n",
            "    üìâ Learning rate reduced: 6.12e-05 ‚Üí 6.86e-05\n",
            "‚úÖ Fold 3 Seed 456 complete: Best Val MAPE = 3.8113% in 22.7min\n",
            "üìà Fold 3 ensemble results:\n",
            "   Mean MAPE: 3.9482% ¬± 0.1653%\n",
            "   Best MAPE: 3.8113%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 67.2 minutes\n",
            "\n",
            "üéØ Training Fold 4 with 3 seeds\n",
            "üöÄ Training Fold 4 with Seed 42\n",
            "‚úÖ Deterministic training setup complete with seed 42\n",
            "  Epoch  1: Train=81.4287%, Val=28.7855%, LR=0.000002, Time=42.4s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 1.90e-06\n",
            "  Epoch  2: Train=26.6369%, Val=14.7210%, LR=0.000087, Time=34.9s\n",
            "    üìâ Learning rate reduced: 1.90e-06 ‚Üí 8.70e-05\n",
            "  Epoch  3: Train=20.8697%, Val=11.3495%, LR=0.000099, Time=42.7s\n",
            "    üìâ Learning rate reduced: 8.70e-05 ‚Üí 9.89e-05\n",
            "  Epoch  4: Train=14.7348%, Val=9.1876%, LR=0.000003, Time=42.2s\n",
            "    üìâ Learning rate reduced: 9.89e-05 ‚Üí 2.60e-06\n",
            "  Epoch  5: Train=12.4335%, Val=7.1810%, LR=0.000019, Time=42.3s\n",
            "    üìâ Learning rate reduced: 2.60e-06 ‚Üí 1.92e-05\n",
            "  Epoch  6: Train=11.9466%, Val=6.9593%, LR=0.000022, Time=42.1s\n",
            "    üìâ Learning rate reduced: 1.92e-05 ‚Üí 2.19e-05\n",
            "  Epoch  7: Train=11.4745%, Val=6.7135%, LR=0.000025, Time=42.5s\n",
            "    üìâ Learning rate reduced: 2.19e-05 ‚Üí 2.51e-05\n",
            "  Epoch  8: Train=10.9205%, Val=6.5395%, LR=0.000027, Time=42.6s\n",
            "    üìâ Learning rate reduced: 2.51e-05 ‚Üí 2.75e-05\n",
            "  Epoch  9: Train=10.5694%, Val=6.3020%, LR=0.000031, Time=42.8s\n",
            "    üìâ Learning rate reduced: 2.75e-05 ‚Üí 3.08e-05\n",
            "    üìâ Learning rate reduced: 3.08e-05 ‚Üí 2.88e-05\n",
            "  Epoch 11: Train=9.5917%, Val=5.8518%, LR=0.000037, Time=33.1s\n",
            "    üìâ Learning rate reduced: 2.88e-05 ‚Üí 3.74e-05\n",
            "  Epoch 12: Train=9.3040%, Val=5.5737%, LR=0.000042, Time=42.8s\n",
            "    üìâ Learning rate reduced: 3.74e-05 ‚Üí 4.16e-05\n",
            "  Epoch 13: Train=8.8158%, Val=5.5556%, LR=0.000042, Time=42.7s\n",
            "    üìâ Learning rate reduced: 4.16e-05 ‚Üí 4.19e-05\n",
            "    üìâ Learning rate reduced: 4.19e-05 ‚Üí 3.87e-05\n",
            "  Epoch 15: Train=8.0956%, Val=5.0777%, LR=0.000049, Time=33.9s\n",
            "    üìâ Learning rate reduced: 3.87e-05 ‚Üí 4.93e-05\n",
            "  Epoch 16: Train=7.9072%, Val=4.8272%, LR=0.000053, Time=42.1s\n",
            "    üìâ Learning rate reduced: 4.93e-05 ‚Üí 5.32e-05\n",
            "  Epoch 17: Train=7.5171%, Val=4.7700%, LR=0.000054, Time=42.5s\n",
            "    üìâ Learning rate reduced: 5.32e-05 ‚Üí 5.41e-05\n",
            "    üìâ Learning rate reduced: 5.41e-05 ‚Üí 4.41e-05\n",
            "  Epoch 19: Train=7.1447%, Val=4.6148%, LR=0.000056, Time=33.4s\n",
            "    üìâ Learning rate reduced: 4.41e-05 ‚Üí 5.65e-05\n",
            "  Epoch 20: Train=6.9265%, Val=4.4404%, LR=0.000059, Time=42.3s\n",
            "    üìâ Learning rate reduced: 5.65e-05 ‚Üí 5.92e-05\n",
            "  Epoch 21: Train=6.6814%, Val=4.4401%, LR=0.000059, Time=42.1s\n",
            "    üìâ Learning rate reduced: 5.92e-05 ‚Üí 5.92e-05\n",
            "    üìâ Learning rate reduced: 5.92e-05 ‚Üí 5.42e-05\n",
            "    üìâ Learning rate reduced: 5.42e-05 ‚Üí 5.68e-05\n",
            "    üìâ Learning rate reduced: 5.68e-05 ‚Üí 5.71e-05\n",
            "  Epoch 25: Train=6.1961%, Val=4.1666%, LR=0.000063, Time=33.4s\n",
            "    üìâ Learning rate reduced: 5.71e-05 ‚Üí 6.33e-05\n",
            "  Epoch 26: Train=6.1478%, Val=4.1235%, LR=0.000064, Time=42.1s\n",
            "    üìâ Learning rate reduced: 6.33e-05 ‚Üí 6.40e-05\n",
            "    üìâ Learning rate reduced: 6.40e-05 ‚Üí 6.15e-05\n",
            "  Epoch 28: Train=6.0875%, Val=4.0840%, LR=0.000065, Time=33.0s\n",
            "    üìâ Learning rate reduced: 6.15e-05 ‚Üí 6.45e-05\n",
            "    üìâ Learning rate reduced: 6.45e-05 ‚Üí 6.30e-05\n",
            "    üìâ Learning rate reduced: 6.30e-05 ‚Üí 6.34e-05\n",
            "  Epoch 31: Train=5.6621%, Val=4.2602%, LR=0.000062, Time=34.0s\n",
            "    üìâ Learning rate reduced: 6.34e-05 ‚Üí 6.19e-05\n",
            "  Epoch 32: Train=5.6667%, Val=4.0087%, LR=0.000066, Time=33.6s\n",
            "    üìâ Learning rate reduced: 6.19e-05 ‚Üí 6.57e-05\n",
            "    üìâ Learning rate reduced: 6.57e-05 ‚Üí 6.13e-05\n",
            "    üìâ Learning rate reduced: 6.13e-05 ‚Üí 5.68e-05\n",
            "  Epoch 35: Train=5.3891%, Val=3.8174%, LR=0.000068, Time=33.5s\n",
            "    üìâ Learning rate reduced: 5.68e-05 ‚Üí 6.85e-05\n",
            "‚úÖ Fold 4 Seed 42 complete: Best Val MAPE = 3.8174% in 23.2min\n",
            "üöÄ Training Fold 4 with Seed 123\n",
            "‚úÖ Deterministic training setup complete with seed 123\n",
            "  Epoch  1: Train=59.7339%, Val=24.9223%, LR=0.000016, Time=42.1s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 1.59e-05\n",
            "  Epoch  2: Train=23.9064%, Val=13.3841%, LR=0.000093, Time=34.1s\n",
            "    üìâ Learning rate reduced: 1.59e-05 ‚Üí 9.32e-05\n",
            "  Epoch  3: Train=18.1310%, Val=10.9662%, LR=0.000099, Time=42.9s\n",
            "    üìâ Learning rate reduced: 9.32e-05 ‚Üí 9.94e-05\n",
            "  Epoch  4: Train=13.6581%, Val=8.9286%, LR=0.000004, Time=42.7s\n",
            "    üìâ Learning rate reduced: 9.94e-05 ‚Üí 3.78e-06\n",
            "  Epoch  5: Train=11.9599%, Val=7.4544%, LR=0.000016, Time=42.6s\n",
            "    üìâ Learning rate reduced: 3.78e-06 ‚Üí 1.60e-05\n",
            "  Epoch  6: Train=11.4407%, Val=7.3494%, LR=0.000017, Time=42.7s\n",
            "    üìâ Learning rate reduced: 1.60e-05 ‚Üí 1.72e-05\n",
            "  Epoch  7: Train=10.9602%, Val=6.7513%, LR=0.000025, Time=42.4s\n",
            "    üìâ Learning rate reduced: 1.72e-05 ‚Üí 2.46e-05\n",
            "  Epoch  8: Train=10.5753%, Val=6.7244%, LR=0.000025, Time=42.3s\n",
            "    üìâ Learning rate reduced: 2.46e-05 ‚Üí 2.50e-05\n",
            "  Epoch  9: Train=10.2406%, Val=6.5260%, LR=0.000028, Time=42.8s\n",
            "    üìâ Learning rate reduced: 2.50e-05 ‚Üí 2.77e-05\n",
            "  Epoch 10: Train=9.8148%, Val=6.4094%, LR=0.000029, Time=42.8s\n",
            "    üìâ Learning rate reduced: 2.77e-05 ‚Üí 2.93e-05\n",
            "  Epoch 11: Train=9.3563%, Val=5.9932%, LR=0.000035, Time=42.3s\n",
            "    üìâ Learning rate reduced: 2.93e-05 ‚Üí 3.53e-05\n",
            "    üìâ Learning rate reduced: 3.53e-05 ‚Üí 3.34e-05\n",
            "  Epoch 13: Train=8.6955%, Val=5.7700%, LR=0.000039, Time=33.5s\n",
            "    üìâ Learning rate reduced: 3.34e-05 ‚Üí 3.86e-05\n",
            "  Epoch 14: Train=8.3086%, Val=5.6276%, LR=0.000041, Time=42.4s\n",
            "    üìâ Learning rate reduced: 3.86e-05 ‚Üí 4.08e-05\n",
            "    üìâ Learning rate reduced: 4.08e-05 ‚Üí 3.83e-05\n",
            "  Epoch 16: Train=7.9139%, Val=5.0242%, LR=0.000050, Time=33.3s\n",
            "    üìâ Learning rate reduced: 3.83e-05 ‚Üí 5.01e-05\n",
            "  Epoch 17: Train=7.5574%, Val=4.9832%, LR=0.000051, Time=42.5s\n",
            "    üìâ Learning rate reduced: 5.01e-05 ‚Üí 5.08e-05\n",
            "    üìâ Learning rate reduced: 5.08e-05 ‚Üí 4.71e-05\n",
            "    üìâ Learning rate reduced: 4.71e-05 ‚Üí 4.85e-05\n",
            "  Epoch 20: Train=6.8672%, Val=4.8252%, LR=0.000053, Time=33.9s\n",
            "    üìâ Learning rate reduced: 4.85e-05 ‚Üí 5.32e-05\n",
            "  Epoch 21: Train=6.7911%, Val=4.7200%, LR=0.000055, Time=42.6s\n",
            "    üìâ Learning rate reduced: 5.32e-05 ‚Üí 5.48e-05\n",
            "    üìâ Learning rate reduced: 5.48e-05 ‚Üí 5.31e-05\n",
            "    üìâ Learning rate reduced: 5.31e-05 ‚Üí 5.27e-05\n",
            "  Epoch 24: Train=6.4115%, Val=4.6563%, LR=0.000056, Time=33.4s\n",
            "    üìâ Learning rate reduced: 5.27e-05 ‚Üí 5.58e-05\n",
            "  Epoch 25: Train=6.3457%, Val=4.5822%, LR=0.000057, Time=41.8s\n",
            "    üìâ Learning rate reduced: 5.58e-05 ‚Üí 5.70e-05\n",
            "  Epoch 26: Train=6.3544%, Val=4.3473%, LR=0.000061, Time=42.4s\n",
            "    üìâ Learning rate reduced: 5.70e-05 ‚Üí 6.06e-05\n",
            "    üìâ Learning rate reduced: 6.06e-05 ‚Üí 5.51e-05\n",
            "    üìâ Learning rate reduced: 5.51e-05 ‚Üí 5.87e-05\n",
            "    üìâ Learning rate reduced: 5.87e-05 ‚Üí 4.98e-05\n",
            "    üìâ Learning rate reduced: 4.98e-05 ‚Üí 5.72e-05\n",
            "  Epoch 31: Train=5.8470%, Val=4.2064%, LR=0.000063, Time=33.3s\n",
            "    üìâ Learning rate reduced: 5.72e-05 ‚Üí 6.27e-05\n",
            "    üìâ Learning rate reduced: 6.27e-05 ‚Üí 5.64e-05\n",
            "    üìâ Learning rate reduced: 5.64e-05 ‚Üí 5.42e-05\n",
            "    üìâ Learning rate reduced: 5.42e-05 ‚Üí 4.92e-05\n",
            "    üìâ Learning rate reduced: 4.92e-05 ‚Üí 6.26e-05\n",
            "‚úÖ Fold 4 Seed 123 complete: Best Val MAPE = 4.2064% in 23.1min\n",
            "üöÄ Training Fold 4 with Seed 456\n",
            "‚úÖ Deterministic training setup complete with seed 456\n",
            "  Epoch  1: Train=72.6435%, Val=26.5515%, LR=0.000008, Time=34.1s\n",
            "    üìâ Learning rate reduced: 1.00e-04 ‚Üí 8.09e-06\n",
            "  Epoch  2: Train=26.5890%, Val=15.1771%, LR=0.000085, Time=34.1s\n",
            "    üìâ Learning rate reduced: 8.09e-06 ‚Üí 8.45e-05\n",
            "  Epoch  3: Train=20.2260%, Val=11.5088%, LR=0.000099, Time=42.1s\n",
            "    üìâ Learning rate reduced: 8.45e-05 ‚Üí 9.86e-05\n",
            "  Epoch  4: Train=14.9842%, Val=8.9860%, LR=0.000003, Time=42.0s\n",
            "    üìâ Learning rate reduced: 9.86e-05 ‚Üí 3.49e-06\n",
            "  Epoch  5: Train=12.7214%, Val=7.2559%, LR=0.000018, Time=42.2s\n",
            "    üìâ Learning rate reduced: 3.49e-06 ‚Üí 1.83e-05\n",
            "  Epoch  6: Train=12.2340%, Val=7.1345%, LR=0.000020, Time=43.0s\n",
            "    üìâ Learning rate reduced: 1.83e-05 ‚Üí 1.97e-05\n",
            "  Epoch  7: Train=11.7078%, Val=6.7732%, LR=0.000024, Time=42.6s\n",
            "    üìâ Learning rate reduced: 1.97e-05 ‚Üí 2.43e-05\n",
            "  Epoch  8: Train=11.1348%, Val=6.7465%, LR=0.000025, Time=42.2s\n",
            "    üìâ Learning rate reduced: 2.43e-05 ‚Üí 2.47e-05\n",
            "  Epoch  9: Train=10.6478%, Val=6.3048%, LR=0.000031, Time=42.7s\n",
            "    üìâ Learning rate reduced: 2.47e-05 ‚Üí 3.08e-05\n",
            "  Epoch 10: Train=10.2592%, Val=6.0117%, LR=0.000035, Time=42.3s\n",
            "    üìâ Learning rate reduced: 3.08e-05 ‚Üí 3.50e-05\n",
            "  Epoch 11: Train=9.7501%, Val=5.8409%, LR=0.000038, Time=42.7s\n",
            "    üìâ Learning rate reduced: 3.50e-05 ‚Üí 3.76e-05\n",
            "    üìâ Learning rate reduced: 3.76e-05 ‚Üí 3.64e-05\n",
            "  Epoch 13: Train=8.9094%, Val=5.5530%, LR=0.000042, Time=33.5s\n",
            "    üìâ Learning rate reduced: 3.64e-05 ‚Üí 4.19e-05\n",
            "    üìâ Learning rate reduced: 4.19e-05 ‚Üí 3.89e-05\n",
            "  Epoch 15: Train=8.3336%, Val=5.4374%, LR=0.000044, Time=33.5s\n",
            "    üìâ Learning rate reduced: 3.89e-05 ‚Üí 4.37e-05\n",
            "  Epoch 16: Train=7.9001%, Val=5.1406%, LR=0.000048, Time=42.5s\n",
            "    üìâ Learning rate reduced: 4.37e-05 ‚Üí 4.83e-05\n",
            "  Epoch 17: Train=7.8486%, Val=4.9280%, LR=0.000052, Time=42.5s\n",
            "    üìâ Learning rate reduced: 4.83e-05 ‚Üí 5.16e-05\n",
            "  Epoch 18: Train=7.6150%, Val=4.8320%, LR=0.000053, Time=42.7s\n",
            "    üìâ Learning rate reduced: 5.16e-05 ‚Üí 5.31e-05\n",
            "  Epoch 19: Train=7.2234%, Val=4.7937%, LR=0.000054, Time=42.3s\n",
            "    üìâ Learning rate reduced: 5.31e-05 ‚Üí 5.37e-05\n",
            "  Epoch 20: Train=7.1728%, Val=4.6567%, LR=0.000056, Time=42.4s\n",
            "    üìâ Learning rate reduced: 5.37e-05 ‚Üí 5.58e-05\n",
            "  Epoch 21: Train=6.9780%, Val=4.9339%, LR=0.000052, Time=42.4s\n",
            "    üìâ Learning rate reduced: 5.58e-05 ‚Üí 5.15e-05\n",
            "  Epoch 22: Train=6.7307%, Val=4.3391%, LR=0.000061, Time=33.2s\n",
            "    üìâ Learning rate reduced: 5.15e-05 ‚Üí 6.07e-05\n",
            "    üìâ Learning rate reduced: 6.07e-05 ‚Üí 5.15e-05\n",
            "  Epoch 24: Train=6.4889%, Val=4.1403%, LR=0.000064, Time=33.6s\n",
            "    üìâ Learning rate reduced: 5.15e-05 ‚Üí 6.37e-05\n",
            "    üìâ Learning rate reduced: 6.37e-05 ‚Üí 5.83e-05\n",
            "  Epoch 26: Train=6.3263%, Val=4.1615%, LR=0.000063, Time=34.1s\n",
            "    üìâ Learning rate reduced: 5.83e-05 ‚Üí 6.34e-05\n",
            "    üìâ Learning rate reduced: 6.34e-05 ‚Üí 6.27e-05\n",
            "    üìâ Learning rate reduced: 6.27e-05 ‚Üí 6.12e-05\n",
            "    üìâ Learning rate reduced: 6.12e-05 ‚Üí 6.01e-05\n",
            "    üìâ Learning rate reduced: 6.01e-05 ‚Üí 6.36e-05\n",
            "  Epoch 31: Train=5.8023%, Val=3.9731%, LR=0.000066, Time=33.5s\n",
            "    üìâ Learning rate reduced: 6.36e-05 ‚Üí 6.62e-05\n",
            "    üìâ Learning rate reduced: 6.62e-05 ‚Üí 5.81e-05\n",
            "    üìâ Learning rate reduced: 5.81e-05 ‚Üí 5.53e-05\n",
            "  Epoch 34: Train=5.5944%, Val=3.8668%, LR=0.000068, Time=33.4s\n",
            "    üìâ Learning rate reduced: 5.53e-05 ‚Üí 6.78e-05\n",
            "    üìâ Learning rate reduced: 6.78e-05 ‚Üí 6.61e-05\n",
            "‚úÖ Fold 4 Seed 456 complete: Best Val MAPE = 3.8668% in 23.1min\n",
            "üìà Fold 4 ensemble results:\n",
            "   Mean MAPE: 3.9636% ¬± 0.1729%\n",
            "   Best MAPE: 3.8174%\n",
            "   Seeds: [42, 123, 456]\n",
            "   Time: 69.5 minutes\n",
            "\n",
            "============================================================\n",
            "üìä COMPREHENSIVE ENSEMBLE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "üìã Individual Fold Analysis:\n",
            "Fold   Best     Mean     Std      Seeds       \n",
            "--------------------------------------------------\n",
            "0      3.8925   3.9710   0.0957   3           \n",
            "1      3.8839   3.9522   0.0486   3           \n",
            "2      3.9581   4.0084   0.0377   3           \n",
            "3      3.8113   3.9482   0.1653   3           \n",
            "4      3.8174   3.9636   0.1729   3           \n",
            "\n",
            "üéØ Overall Performance Summary:\n",
            "   Total models trained: 15\n",
            "   Overall mean MAPE: 3.9687% ¬± 0.1204%\n",
            "   Best single model: 3.8113%\n",
            "   Expected ensemble MAPE: 3.9687%\n",
            "   Total training time: 6.64 hours\n",
            "   Average time per model: 26.5 minutes\n",
            "\n",
            "üìà Performance Analysis:\n",
            "   Best single fold performance: 3.8113%\n",
            "   Mean of best fold performances: 3.8726%\n",
            "   Stability improvement: 0.1204% standard deviation\n",
            "\n",
            "üèÜ Competition Analysis:\n",
            "   Models below 3.0% target: 0/15\n",
            "   Success rate: 0.0%\n",
            "   üéØ Gap to target: 0.8113%\n",
            "üíæ Results saved to:\n",
            "   /content/drive/MyDrive/ThinkOnward/Result/Phase2c/ensemble_results.json\n",
            "   /content/drive/MyDrive/ThinkOnward/Result/Phase2c/training_summary.txt\n",
            "\n",
            "‚úÖ Phase 2c Training Complete!\n",
            "Ready for diffusion model development in Phase 3\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyN1SnC5PfvfBY+3Cz5+2Ody",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}